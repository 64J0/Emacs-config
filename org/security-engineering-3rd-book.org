#+TITLE: [book] Security Engineering
#+AUTHOR: Ross Anderson
#+EDITION: 3rd

* About the author
  + Name: Ross Anderson

  Graduated in math and  natural science from Cambridge in the  1970s, and got a
  qualification  in  computer  engineering.  First  working  experience  in  the
  avionics field.  Later studied cryptology  and computer security,  working for
  banks during the 1980s.

  Moved to  academia in 1992  but continued to  consult to industry  on security
  technology. Taught  security and cryptology to  students for a few  years, and
  realized  that the  existing textbooks  were too  narrow and  theoretical: the
  security  textbooks focused  on  the access  control  mechanisms in  operating
  systems, while the cryptology books  developed the theory behind bryptographic
  algorithms and protocols.

* Part I
  + Cover the basics.
  + No fancy background required.

  These  chaperts  cover basic  material,  and  largely  follow what  is  taught
  first-year and second-year  undergraduates at Cambridge. But I  hope that even
  experts will find the case studies of interest and value.

** Chapter 1: What is security engineering?
   Security engineering  is about building  systems to remain dependable  in the
   face  of malice,  error, or  mischance. As  a discipline,  it focuses  on the
   tools, processes, and methods needed  to design, implement, and test complete
   systems, and to adapt existing systems as their environment evolves.

   Security  engineering  requires  cross-disciplinary expertise,  ranging  from
   cryptography and  computer security  through hardware tamper-resistance  to a
   knowledge of economics, applied psychology, organisations and the law. System
   engineering  skills,   from  business   process  analysis   through  software
   engineering to evaluation  and testing, are also important; but  they are not
   sufficient,  as  they  deal  only   with  error  and  mischance  rather  than
   malice. The security engineer also  needs some skill at adversarial thinking,
   just like  a chess  player; you  need to  have studied  lots of  attacks that
   worked in  the past,  from their  openings through  their development  to the
   outcomes.

   Security and safety are becoming ever  more intertwined as we get software in
   everything.

   [...] The  military environment was until  recently one of the  few customers
   for software systems that had to be maintained for decades. Now that software
   and internet connectivity are finding their way into safety-critical consumer
   goods  such  as  cars,  software  sustainability is  becoming  a  much  wider
   concern. In 2019, the European Union passed  a law demanding that if you sell
   goods with  digital components,  you must maintain  those components  for two
   years, or  for longer if  that's a reasonable  expectation of the  customer -
   which  will mean  ten years  for  cars and  white goods.   If you're  writing
   software for  a car of fridge  that will be  on sale for seven  years, you'll
   have to maintain it for almost twenty years. What tools should you use?

   [...] Ignoring the human components, and thus neglecting usability issues, is
   one of the largest causes of security failure.

*** A framework
    To build really dependable systems, you need four things to come together.

    There's policy: what you're supposed to achieve.

    There's mechanism: the ciphers,  access controls, hardware tamper-resistance
    and other machinery that you use to implement the policy.

    There's assurance: the  amount of reliance you can place  on each particular
    mechanism, and how well they work together.

    There's  incentive: the  motive  that people  guarding  and maintaining  the
    system have to do their job properly, and also the motive that the attackers
    have to try to defeat your policy.

*** Definitions
    + System:
      (1) A product or component, such as a cryptographic protocol, a smartcard,
      or the  hardware of a phone,  a laptop or server;

      (2) One or more of the  above plus an operating system, communications and
      other infrastructure;

      (3) The  above plus  one or  more applications  (banking app,  health app,
      media player,  browser, accounts/payroll  package, and  so on  - including
      both client and cloud components);

      (4) any or all of the above plus IT staff;

      (5) any or all of the above plus internal users and management;

      (6) any or all of the above plus customers and other external users;

    + Subject:
      A physical person in any role  including that of an operator, principal or
      victim.

    + Person:
      Either  a  physical  person  or  a  legal person  such  as  a  company  or
      government.

    + Principal:
      Is an entity that participates in a  security system. This entity can be a
      subject, a  person, a  role, or  a piece  of equipment  such as  a laptop,
      phone, smartcard, or card reader. A principal can also be a communications
      channel (which might be  a port number, or a crypto  key, depending on the
      circumstance). A  principal can  also be a  compound of  other principals;
      examples are a  group (Alice or Bob), a conjunction  (Alice and Bob acting
      together),  a  compound  role  (Alice  acting  as  Bob's  manager)  and  a
      delegation (Bob acting for Alice in her absence).

    + Group:
      A set of principals.

    + Role:
      Set of functions assumed by different persons in succession.

    + Identity:
      When we have to be careful, I will use it to mean a correspondence between
      the names of two principals signifying  that they refer to the same person
      or equipment.

    + Trusted:
      [NSA definition]  A trusted system of  component is one whose  failure can
      break the security policy.

    + Trustworthy:
      [NSA definition] A trustworthy system or component is one that won't fail.

    + Secrecy:
      Is an engineering term that refers to the effect of the mechanisms used to
      limit  the  number of  principals  who  can  access information,  such  as
      cryptography os computer access controls.

    + Confidentiality:
      Involves an  obligation to protect  some other person's  or organisation's
      secrets if you know them.

    + Privacy:
      Is  the ability  and/or right  to  protect your  personal information  and
      extends to the ability and/or right  to prevent invasions of your personal
      space  (the  exact  definition  of   which  varies  from  one  country  to
      another). Privacy can extend to families  but not to legal persons such as
      corporations.

    + Hack:
      Something  a  system's  rules  permit, but  which  was  unanticipated  and
      unwanted by its designers.

** Chapter 2 - Who is the opponent?
   Ideologues may deal with the world as they would wish it to be, but engineers
   deal  with the  world as  it is.  If you're  going to  defend systems  agains
   attack, you first need to know who your enemies are.

   Model your enemy:

   + What sort of capabilities will the adversaries have, and what motivation?

   + How certain are you of this assessment, and how might it change over the
     system's lifetime?

*** Spies
    Governments have a range of tools  for both passive surveillance of networks
    and active attacks on computer systems. Hundreds of firms sell equipment for
    wiretapping, for radio  intercept, and for using  various vulnerabilities to
    take over computers, phones and other digital devices.

**** Prism
     A  system to  collect the  Gmail and  other data  of users  who are  not US
     citizens or  permanent residents, and  is carried  out under an  order from
     FISA court.

     Prism was  an internal  NSA codename  for an access  channel that  had been
     privded  to the  FBI  to  conduct warranted  wiretaps.  US  law permits  US
     citizens to be  wiretapped provided an agency convinces a  court to issue a
     warrant,  based on  "probable  cause" that  hey  were up  to  no good;  but
     foreigners could be wiretapped freely.

**** Tempora
     A  program   to  collect   intelligence  from  international   fibre  optic
     cables. [...] the journalist Duncan  Campbell had described a system called
     Echelon in 1988 which tapped  the Intersat satellite network, keeping voice
     calls  on  tape while  making  metadata  available  for searching  so  that
     analysts could select traffic to or from phone numbers of interest. Snowden
     gave us an  update of the technology. In Cornwall  alone, 200 transatlantic
     fibres were tapped  and 46 could be  collected at any one time.  As each of
     these carried  10 Gb/s, the total  data volume could  be as high as  21Pb a
     day,  so  the  incoming  data   feeds  undergo  massive  volume  reduction,
     discarding  video, news  and the  like.  Material was  then selected  using
     selectors - not just phone numbers but more general search terms such as IP
     addresses - and stored for 30 days in case it turns out to be of interest.

**** Muscular
     One of the applications running on  top of Tempora was Muscular. [...] this
     collected data as it flowed between the data centres of large service firms
     such as Yahoo and  Google.  Your mail may have been  encrypted using SSL en
     route to the service's  front end, but it then flowed  in the clear between
     each company's data centres.

     [...] at  a meeting at  Princeton which Snowden attended  in the form  of a
     telepresence robot,  he pointed out  that a lot of  internet communications
     that appear to  be encrypted aren't really, as modern  websites use content
     delivery  networks (CDNs)  such as  Akamai  and Cloudflare;  while the  web
     traffic is encrypted from the user's laptop  or phone to the CDN's point of
     presente at their  ISP, it isn't encrypted on the  backhaul unless they pay
     extra  - which  most of  them don't.  So the  customer thinks  the link  is
     encrypted, and  it's protected from casual  snooping - but not  from nation
     states or from firms who can read backbone traffic.

**** Special collection
     The NSA and CIA jointly operate  the Special Collection Service (SCS) whose
     most visible activity  may be the plastic  panels near the roofs  of US and
     allied embassies worldwide;  these hide antennas for  hoovering up cellular
     communication (a program  known as ‘Stateroom’). Beyond  this, SCS implants
     collection equipment  in foreign telcos, Internet  exchanges and government
     facilities.  This can  involve classical spy tradecraft,  from placing bugs
     that monitor speech or  electronic communications, through recruiting moles
     in target  organisations, to  the covert deployment  of antennas  in target
     countries to tap internal microwave links.

     Close-access  operations  include  Tempest monitoring:  the  collection  of
     infor-  mation  leaked  by  the  electromagnetic  emissions  from  computer
     monitors  and  other equipment,  described  in  19.3.2. The  Snowden  leaks
     disclose the collection  of computer screen data  and other electromagnetic
     emanations  from  a  num-  ber  of countries’  embassies  and  UN  missions
     including those of India, Japan, Slovakia and the EU.

**** Bullrun and Edgehill
     Special  collection  increasingly   involves  supply-chain  tampering.  SCS
     routinely intercepts equipment such as routers being exported from the USA,
     adds surveillance  implants, repackages them  with factory seals  and sends
     them onward to customers.

     Bullrun  is the  NSA  codename,  and Edgehill  the  GCHQ  one, for  'crypto
     enabling', a $100m-a-year program of  tampering with supplies and suppliers
     at all levels of  the stack. [...]  Most of the  actual damage, though, was
     done  by   restrictions  on  cryptographic  key   length,  dovetailed  with
     diplomatic pressure  on allies  to enforce export  controls, so  that firms
     needing  export  licenses   could  have  their  arms  twisted   to  use  an
     'appropriate' standard, and was entangled  with the Crypto Wars. The result
     was  that many  of the  systems in  use today  were compelled  to use  weak
     cryptography, leading to  vulnerabilities in everything from  hotel and car
     door locks  to VPNs.  In addition to  that, supply-chain  attacks introduce
     covert vulnerabilities  into widely-used software; many  nation states play
     this game, along with some private actors.

**** Xkeyscore
     With such a vast collection of data,  you need good tools to search it. The
     Five Eyes search computer data using Xkeyscore, a distributed database that
     enables  an analyst  to search  collected  data remotely  and assemble  the
     results.  Exposed  on July  31  2013,  NSA  documents  describe it  as  its
     "widest-reaching" system for developing intelligence; it enables an analyst
     to  search  emails,  SMSes,  chats,   address  book  entries  and  browsing
     histories.

**** Longhaul
     Bulk key theft  and supply-chain tampering are not the  only ways to defeat
     cryptography. The  Xkeyscore training deck  gives an example: "Show  me all
     the VPN startups  in country X, and give  me the data so I  can decrypt and
     discover  the users".  VPNs  appear  to be  easily  defeated; a  decryption
     service  called  Longhaul ingests  ciphertext  and  returns plaintext.  The
     detailed  description of  cryptoanalytic techniques  is held  as /Extermely
     Compartmented Information/  (ECI) and is  not found in the  Snowden papers,
     but some of them talk of recent breakthroughs in cryptanalysis.

**** Quantum
     There is  a long  history of  attacks on protocols,  which can  be spoofed,
     replayed and manipulated in various ways. The best-documented NSA attack on
     Internet  traffic goes  under  the  codename of  Quantum  and involves  the
     dynamic exploitation of  one of the communication end-points.  Thus, to tap
     an  encrypted SSL/TLS  session to  a webmail  provider, the  Quantum system
     fires a ‘shot’  that exploits the browser.  There are  various flavours; in
     ‘Quantuminsert’, an  injected packet redirects  the browser to  a ‘Foxacid’
     attack server. Other  variants attack software updates  and the advertising
     networks whose code runs in mobile phone apps.

**** CNE (Computer and Network Exploitation)
     Is the generic NSA term for hacking, and  it can be used for more than just
     key theft  or TLS session  hijacking; it can be  used to acquire  access to
     traffic too.

     [...] The  hacking tools  and methods used  by NSA and  its allies  are now
     fairly well understood;  some are shared with law  enforcement. The Snowden
     papers reveal an internal store where  analysts can get a variety of tools;
     a series of leaks  in 2016-7 by the Shadow Brokers  (throught to be Russian
     military intelligence,  the GRU) disclosed  a number of actual  NSA malware
     samples, used  by hackers at the  NSA's Tailored Access Operations  team to
     launch attacks.  (Some of these  tools were  repusposed by the  Russians to
     launch the  NotPetya worm and by  the North Koreans in  Wannacry). The best
     documentation of all is probably about  a separate store of goodies used by
     the  CIA, disclosed  in some  detail to  Wikileaks in  the 'Vault  7' leaks
     in 2017.  These include  manuals for tools  that can be  used to  install a
     remote access Trojan  on your machine, with components to  geolocate it and
     to exfiltrate files (including SSH credentials), audio and video; a tool to
     jump air gaps by infecting thumb  drives; a tool for infecting wifi routers
     so they'll do  man-in-the-middle attacks; and even a  tool for watermarking
     documents so a  whistleblower who leaks them could be  tracked. Many of the
     tools are  available not just for  Windows but also for  MacOS and Android;
     some  infect firmware,  making them  hard to  remove. There  are tools  for
     hacking  TVs   and  IoT   devices  too,  and   tools  to   hamper  forensic
     investigations. The Vault 7 documents  are useful reading if you're curious
     about the specifications  and manuals for modern government  malware. As an
     example of the  law-enforcement use of such tools, in  June 2020 it emerged
     that  the French  police  in  Lille had  since  2018  installed malware  on
     thousands of Android phones running  EncroChat, an encrypted message system
     favoured by  criminals, leading to the  arrest of 800 criminal  suspects in
     France, the  Netherlands, the UK  and elsewhere, as  well as the  arrest of
     several police officers  for corruption and the seizure of  several tons of
     drugs.

**** Offensive operations
     The Director NSA also heads the US Cyber Command, which since 2009 has been
     one of ten unified commands of  the United States Department of Defense. It
     is responsible for offensive cybe operations,  of which the one that made a
     real difference  was Stuxnet.  This  was a  worm designed to  damage Iran's
     uranium enrichment centrifuges by speeding them up and slowing them down in
     patters designed to  cause mechanical damage, and was  developed jointly by
     the USA  and Israel. Is  was technically sophisticated, using  for zero-day
     exploits and  two stolen code-signing certificates  to spread promiscuously
     through Windows PCs, until it  found Siemens programmable logic controllers
     of the type  used at Iran's Natanz  enrichment plant - where  it would then
     install a rootkit  that would issue the destructive commands,  while the PC
     assured  the  operators  that  everything   was  fine.  It  was  apparently
     introduced using USB  drives to bridge the air gap  to the Iranian systems,
     and came to light  in 2010 after copies had somehow  spread to central Asia
     and Indonesia.

     Stuxnet acted  as a  wake-up call  for other  governments, which  rushed to
     acquire 'cyber-weapons'  and develop  offensive cyber doctrine  - a  set of
     principles for  what cyber warriors  might do, developed with  some thought
     given to  rationale, strategy, tactics and  legality. Oh, and the  price of
     zero-day vulnerabilities rose sharply.

**** Attack scaling
     Computer  scientists  know the  importance  of  how algorithms  scale,  and
     exactly  the same  holds  for attacks.  Tapping a  single  mobile phone  is
     hard.  You  have  to  drive  around  behind  the  suspect  with  radio  and
     cryptanalysis  gear in  your car,  risk being  spotted, and  hope that  you
     manage  to  catch the  suspect’s  signal  as they  roam  from  one cell  to
     another. Or you can drive behind them  with a false base station 7 and hope
     their phone will roam  to it as the signal is louder  than the genuine one;
     but then  you risk electronic detection  too. Both are highly  skilled work
     and low-yield: you lose the signal maybe  a quarter of the time.  So if you
     want to wiretap someone in central Paris often enough, why not just wiretap
     everyone? Put  antennas on  your embassy  roof, collect  it all,  write the
     decrypted  calls and  text messages  into a  database, and  reconstruct the
     sessions electronically. If  you want to hack everyone in  France, hack the
     telco,  perhaps by  subverting the  equipment it  uses. At  each stage  the
     capital cost goes up but the marginal  cost of each tap goes down. The Five
     Eyes strategy is  essentially to collect everything in the  world; it might
     cost billions to  establish and maintain the infrastructure,  but once it’s
     there you have everything.

*** China
    China is  now the leading  competitor to the USA,  being second not  just in
    terms of GDP (gross domestic product,  similar to /PIB/) but as a technology
    powerhouse. The  Chinese lack the NSA's  network of alliances and  access to
    global infrastructure (although they're working  hard at that). Within China
    itself, however,  they demand  unrestricted access to  local data.  [...] In
    2008, it  emerged that  the version  of Skype available  in Chinas  had been
    modified so that  messages were scanned for sensitive keywords  and, if they
    were found, the user's texts were uploaded to a server in China.

    [...]

    By 2020 the attacks had become more sophisticated, with a series of advanced
    persistent threats (APTs)  tracked by threat intelligence  firms. A campaign
    to hack  the phones of Uighurs  involved multiple zero-day attacks,  even on
    iPhones, that were delivered via  compromised Uighur websites; this targeted
    not  only  Uighurs in  China  but  the  diaspora  too. China  also  conducts
    industrial and commercial espionage, and Western agencies claim they exploit
    managed service  providers. Another  approach was attacking  software supply
    chains; a Chinese group variously  called Wicked Panda or Barium compromised
    software updates  from computer maker Asus,  a PC cleanup tool  and a Korean
    remote management tool, as well as three popular computer games, getting its
    malware installed  on millions  of machines;  rather than  launching banking
    trojans or ransomware, it was then used for spying.

    [...]

    Since 2018 there has been a  political row over whether Chinese firms should
    be permitted to sell routers and 5G  network hardware in NATO (same as OTAN)
    countries,   with   the   Trump  administration   blacklisting   Huawei   in
    May 2019. There had been a previous  spat over another Chinese firm, ZTE; in
    2018 GCHQ (Government Communications Headquarters) warned that ZTE equipment
    "would present  risk to  UK national  security that  could not  be mitigated
    effectively  or  practicably".  President  Trump  banned  ZTE  for  breaking
    sanctions on  North Korea and Iran,  but relented and allowed  its equipment
    back in the USA subject to security controls.

    [...]

    The UK banned the purchase of their telecomms equipment from the end of 2020
    and said it  would remove it from  UK networks by 2027.  Meanwhile, China is
    helping many  less developed  countries modernise  their networks,  and this
    access may help them rival the Five Eyes' scope in due course. Trade policy,
    industrial policy and cyber-defense strategy have become interwined in a new
    Cold War.

    Strategically, the question  may not be just whether China  could use Huawei
    routers to wiretap  other countries at scale, so much  as whether they could
    use  it in  time of  tension to  launch DDoS  attacks that  would break  the
    Internet by subverting BGP routing.

*** Russia
    Russia, like China, lacks America's  platform advantage and compensates with
    hacking teams  that use spear-phishing  and malware. Unlike China,  it takes
    the  low  road, acting  frequently  as  a  spoiler,  trying to  disrupt  the
    international order,  and sometimes  benefiting directly via  a rise  in the
    price of oil, its main export.

    [...]  Russia  took  down  30 electricity  substations  on  three  different
    distribution  systems within  half an  hour  of each  other, leaving  230000
    people  without  electricity  for  several  hours.  They  involved  multiple
    different attack  vectors that had been  implanted over a period  of months,
    and since they followed a Ukrainian attack on power distribution in Crimea -
    and  switched equipment  off when  they could  have destroyed  it instead  -
    seemed  to have  been intended  as  a warning.  This attack  was still  tiny
    compared with the other effects of the conflict, which included the shooting
    down of a Malaysian Airlines airliner with  the loss of all on board; but it
    was the first cyber-attack to disrupt  mains electricity. Finally on June 27
    2017 came  the NotPetya attack  - by far  the most damaging  cyber-attack to
    date.

    The NotPetya  worm was  initially distributed using  the update  service for
    MeDoc,  the accounting  software used  by  the great  majority of  Ukrainian
    businesses.  It  then  spread  laterally  in  organisations  across  Windows
    file-shares  using the  EternalBlue vulnerability,  an NSA  exploit with  an
    interesting  history.  From  March 2016,  a  Chinese gang  started using  it
    against targets  in Vietnam,  Hong Kong  and the  Philippines, perhaps  as a
    result  of finding  and reverse  engineering it  (it’s said  that you  don’t
    launch a  cyberweapon; you share  it).  It was leaked  by a gang  called the
    ‘Shadow  Brokers’ in  April 2017,  along with  other NSA  software that  the
    Chinese didn’t deploy,  and then used by the Russians  in June. The NotPetya
    worm  used  EternalBlue  together  with  the  Mimikatz  tool  that  recovers
    passwords  from  Windows   memory.  The  worm’s  payload   pretended  to  be
    ransomware; it  encrypted the infected  computer’s hard disk and  demanded a
    ransom of $300 in  bitcoin. But there was no mechanism  to decrypt the files
    of  computer owners  who paid  the ransom,  so it  was really  a destructive
    service-denial worm.  The only  way to  deal with it  was to  re-install the
    operating system and restore files from backup.

*** Crooks
    Cybercrime is now about  half of all crime, both by volume  and by value, at
    least in developed countries.

**** Malware devs
     In addition to the several hundred software engineers who write malware for
     the  world's intelligence  agencies  and their  contractors,  there may  be
     hundreds of people  writing malware for the criminal  market; nobody really
     knows (though we can monitor traffic on hacker forums to guess the order of
     magnitude).

     Within this  community there are  specialists. Some concentrate  on turning
     vulnerabilities  into  exploits, a  nontrivial  task  for modern  operating
     systems  that  use  stack  canaries,   ASLR  and  other  techniques.  Other
     specialise in  the remote access  Trojans that the exploits  install; other
     build the  peer-to-peer and DGA software  for resilient command-and-control
     communications; yet others design specialised  payloads for bank fraud. The
     highest-value  operations seem  to  be platforms  that  are maintaned  with
     constant  upgrades  to  cope  with  the  latest  countermeasures  from  the
     anti-virus  companies.  Within each  specialist  market  segment there  are
     typically a  handful of operators,  so that when we  arrest one of  them it
     makes a difference for a while.

**** Ransomware
     A number of professional gangs  penetrate systems, install ransomware, wait
     until several days  or weeks of backup data have  been encrypted and demand
     substantial sums of bitcoin.

** Chapter 3 - Psychology and Usability
   Deception, of  various kinds, is now  the principal mechanism used  to defeat
   online security. It can be used  to get passwords, to compromise confidential
   information  or to  manipulate  financial transactions  directly. Hoaxes  and
   frauds have always happened, but the Internet makes some of them easiers, and
   lets others be  repackaged in ways that may bypass  our existing controls (be
   they personal intuitions, company procedures or even laws).

   Another driver for  the surge in attacks based on  social engineering is that
   people are getting better at technology.  As designers learn how to forestall
   the easier technical  attacks, psychological manipulation of  system users or
   operators becomes ever  more attractive. So the  security engineer absolutely
   must understand  basic psycology, as  a prerequisite for  dealing competently
   with  everything from  passwords  to  CAPTCHAs and  from  phishing to  social
   engineering  in general;  a working  appreciation of  risk misperception  and
   scaremongering  is also  necessary  to understand  the mechanisms  underlying
   angry online mobs and the societal  response to emergencies from terrorism to
   pandemic disease.  So just as  research in security  economics led to  a real
   shift in  perspective between  the first  and second  editions of  this book,
   research in  security psychology has  made much of  the difference to  how we
   view the world between the second edition and this one.

*** Insights from psychology research

**** Cognitive psychology
     Is the classical approach to the subject - building on early empirical work
     in  the nineteenth  century. It  deals with  how we  think, remember,  make
     decisions  and even  daydream.   Twentieth-century pioneers  such as  Ulric
     Neisser discovered  that human memory  doesn't work like a  video recorder:
     our memories are  stored in networks across the brain,  from which they are
     reconstructed,  so they  change  over  time and  can  be manipulated.  Some
     well-known results:

     + It's easier to memorise things that are repeated frequently.
     + It's easier to store things in context.

**** Gender, diversity and interpersonal variation
     Many women  die because medical  tests and technology assume  that patients
     are men,  or because engineers  use male crash-test dummies  when designing
     cars;  protective   equipment,  from   sportswear  through   stab-vests  to
     spacesuits, gets tailored  for men by default. So do  we have problems with
     information systems too?  They are designed by men, and  young geeky men at
     that, yet over half  their users may be women. This  realisation has led to
     research on gender HCI (Human Computer  Interface) - on how software should
     be designed  so that women can  also use it effectively.  Early experiments
     started  from the  study of  behaviour: experiments  showed that  women use
     peripheral vision more, and it duly  turned out that larger displays reduce
     gender bias. Work on American female programmers suggested that they tinker
     less than males, but more effectively. But how much is nature, and how much
     nurture? Societal  factors matter, and  US women  who program appear  to be
     more thoughtful, but lower self-esteem  and higher risk-aversion leads them
     to use fewer features.

     [...] Might  this explain why men  are more interested in  computer science
     than women,  with women consistently taking  about a sixth of  CS places in
     the USA and the UK? But here, we run into trouble. Women make up a third of
     CS students  in the former communist  countries of Poland, Romania  and the
     Baltic states, while numbers in India are close to equal. Male dominance of
     software is  also a  fairly recent  phenomenon. When I  started out  in the
     1970s, there were almost as many women  programmers as men, and many of the
     pioneers  were women,  whether in  industry, academia  or government.  This
     suggests that  the relevant differences  are more cultural than  genetic or
     developmental.

**** Social psychology
     This  attempts to  explain how  the  thoughts, feelings,  and behaviour  of
     individuals are influenced by the  actual, imagined, or implied presence of
     others. It  has many  aspects, from  the identity  that people  derive from
     belonging to  groups - whether of  gender, tribe, team, profession  or even
     religion  - through  the self-esteem  we  get by  comparing ourselves  with
     others.

**** The social-brain theory of deception
     :TODO:

**** Heuristics, biases and behavioural economics
     One field of psychology that has been applied by security researchers since
     the mid-2000s  has been /decision science/,  which sits at the  boundary of
     psycology and economics and studies the heuristics that people use, and the
     biases that  influence them,  when making  decisions. It  is also  known as
     /behavioural economics/, as it examines the ways in which people's decision
     processes depart from the rational behaviour modeled by economists.

***** Prospect theory and risk misperception
      Kahneman and  Tversky did extensive  experimental work on how  people made
      decisions faced  with uncertainty. They first  developed /prospect theory/
      which models risk  appetite: in many circumstances,  people dislike losing
      $100  they already  have more  than they  value winning  $100. Framing  an
      action  as  avoiding a  loss  can  make people  more  likely  to take  it;
      phishermen hook people  by sending messages like 'Your  PayPal account has
      been frozen, and you need to click here to unlock it.'

      - We often base a judgement on an initial guess or comparison and then adjust
        it if need be - the /anchoring effect/;
      - We base inferences on the ease of bringing examples to mind - the /availability heuristic/,
        which was OK for lion attacks 50 thousand years ago but gives the wrong answers when
        mass media bombard us with images of terrorism;
      - We're more likely to be sceptical about things we've heard than about things
        we've seen, perhaps as we have more neurons processing vision;
      - We worry too much about events that are very unlikely but have very bad consequences;
      - We're more likely to believe things we've worked out for ouselves rather than
        things we've been told.

***** Present bias and hyperbolic discounting
      [...] /Hyperbolic discounting/  is a model used by  decision scientists to
      quantify present bias. Intuitive reasoning  may lead people to use utility
      functions that discount the future  so deeply that immediate gratification
      seems to  be the best  course of action, even  when it isn't.  Such models
      have been applied to try to explain the /privacy paradox/ - why people say
      in surveys that they care about privacy but act otherwise online.

***** Defaults and nudges
      [...]  Many people  usually take  the easiest  path and  use the  standard
      configuration of  a system, as they  assume it will be  good enough. [...]
      For example, if a firm's staff are  enrolled in a pension plan by default,
      most will  not bother  to opt out,  while if it's  optional most  will not
      bother to  opt in.  A second  example is  that many  more organs  are made
      available for  transplant in  Spain, where  the law  lets a  dead person's
      organs be used unless they objected,  than in Britain where donors have to
      consent actively. A third example is that tax evasion can be cut by having
      the taxpayer  declare that the information  in the form is  true when they
      start to fill  it out, rather than  at the end. The set  of choices people
      have to make, the order in which  they make them, and the defaults if they
      do nothing, are called the /choice architecture/.

      Defaults matter in security too, but often they are set by an adversary so
      as  to  trip  you  up.  For example,  Facebook  defaults  to  fairly  open
      information sharing,  and whenever enough  people have figured out  how to
      increase their privacy  settings, the architecture is changed  so you have
      to opt out  all over again. This exploits not  just hazardous defaults but
      also the control paradox – providing the illusion of control causes people
      to  share more  information. We  like  to feel  in control;  we feel  more
      comfortable driving  in our cars  than letting someone  else fly us  in an
      airplane – even if  the latter is an order of  magnitude safer. “Pri- vacy
      control settings give people more  rope to hang themselves,” as behavioral
      economist George Loewenstein  puts it. “Facebook has figured  this out, so
      they give you incredibly granular controls.”

***** The affect heuristic
      [...] The idea  is that while the human brain  can handle multiple threads
      of cognitive  processing, our emotions remain  resolutely single-threaded,
      and they are  even less good ar probability theory  than the rational part
      of our brains. So by making emotion salient, a marketer or a fraudster can
      try to get  you to answer questions using emotion  rather than reason, and
      using heuristics rather than calculation.

      So it  should not  surprise anyone  that porn websites  have been  used to
      install a lot of malware - as have church websites, which are often poorly
      maintained and  easy to hack.  Similarly, events  that evoke a  feeling of
      dread -  from cancer to  terrorism - not only  scare people more  than the
      naked probabilities justify,  but also make those  probabilities harder to
      calculate, and deter people from even making the effort.

      Other factors that can reinforce our  tendency to explain things by intent
      include cognitive  overload, where the  rational part of the  brain simply
      gets tired. Our capacity for self-control  is also liable to fatigue, both
      physical and mental; some mental  arithmetic will increase the probability
      that we’ll pick up a chocolate rather than an apple. So a bank that builds
      a busy  website may  be able to  sell more life  insurance, but  it’s also
      likely to make its customers more vulnerable to phishing.

*** Deception in practice
    Not only do  marketers push the most profitable option  rather than the best
    value, but they  use every other available trick  too. Stanford’s Persuasive
    Technology Lab  has been at the  forefront of developing techniques  to keep
    people  addicted to  their  screens,  and one  of  their alumni,  ex-Googler
    Tristan  Harris,  has become  a  vocal  critic.  Sometimes  dubbed  ‘Silicon
    valley’s conscience’, he  explains how tech earns its  money by manipulating
    not  just   defaults  but   choices,  and   asks  how   this  can   be  done
    ethically. Phones and other screens  present menus and thus control choices,
    but there’s  more to  it than  that. Two techniques  that screens  have made
    mainstream are the casino’s technique of using intermittent variable rewards
    to create addiction (we  check our phones 150 times a day  to see if someone
    has rewarded  us with attention)  and bottomless  message feeds (to  keep us
    consuming even  when we aren’t  hungry any more).  But there are  many older
    techniques that predate computers.

**** The salesman and the scamster
     Deception is  the twin brother of  marketing, so one starting  point is the
     huge  literature  about sales  techniques.  One  eminent writer  is  Robert
     Cialdini, a  psychology professor who  took summer jobs  selling everything
     from used cars to home improvements and life insurance in order to document
     the tricks  of the  trade. His  book 'Influence:  Science and  Practice' is
     widely  read by  sales  professionals  and describes  six  main classes  of
     technique used to influence people and close a sale.

     1. Reciprocity:
        Most people feel the need to return favours;
     2. Commitment and consistency:
        People  suffer   cognitive  dissonance   if  they  feel   they're  being
        inconsistent;
     3. Social proof:
        Most people want the approval of  others. This means following others in
        a  group of  which  they're a  member,  and the  smaller  the group  the
        stronger the pressure;
     4. Liking:
        Most people want to do what  a good-looking or otherwise likeable person
        asks;
     5. Authority:
        Most people  are deferential  to authority  figures (recall  the Milgran
        study mentioned above);
     6. Scarcity:
        We're afraid of  missing out, if something we might  want could suddenly
        be unavailable.

**** Social engineering
     Hacking systems  through the people who  operate them is not  net. Military
     and  intelligence organizations  have always  targeted each  other's staff;
     most of  the intelligence successes  of the old  Soviet Union were  of this
     kind. Private investigation agencies have not been far behind.

     + Kevin Mitnick's 'Art of Deception'.

     [...] Amid growing  publicity about social engineering, there  was an audit
     of  the   IRS  in  2007   by  the   Treasury  Inspector  General   for  Tax
     Administration, whose staff  called 102 IRS employees at  all levels, asked
     for their  user IDs,  and told them  to change their  passwords to  a known
     value; 62 did  so. What’s worse, this happened despite  similar audit tests
     in 2001 and 2004  [1676]. Since then, a number of  audit firms have offered
     social engineering as a service; they phish their audit clients to show how
     easy it is. Since the mid-2010s, opinion has shifted against this practice,
     as it causes a  lot of distress to staff without  chang- ing behaviour very
     much.

**** Phishing
     While phone-based  social engineering was  the favoured tactic of  the 20th
     century, online  phishing seems to have  replaced it as the  main tactic of
     the 21st.

     [...] The word 'phishing'  appeared in 1996 in the context  of the theft of
     AOL passwords. By  then, attempts to crack email accounts  to send spam had
     become  common enough  for AOL  to  have a  'report password  solicitation'
     button on its web page; and the first reference to 'password fishing' is in
     1990, in the  context of people altering terminal firmware  to collect Unix
     logon passwords.

**** Opsec
     Getting your  staff to resist attempts  by outsiders to inveigle  them into
     revealing secrets, whether  over the phone or online, is  known in military
     circles  as /operational  security/  or opsec.  Protecting really  valuable
     secrets, such  as unpublished  financial data,  not-yet-patented industrial
     research and military plans, depends on  limiting the number of people with
     access, and  also on doctrines  about what may  be discussed with  whom and
     how. It's not  enough for rules to  exist; you have to train  the staff who
     have access, explain the reasons behind  the rules, and embed them socially
     in the organisation.

**** Deception research
     Since 9/11, huge amounts of money  have been spent by governments trying to
     find  better lie  detectors, and  deception researchers  are funded  across
     about five subdisciplines of psychology.  The polygraph measures stress via
     heart rate and skin conductance; it has  been around since the 1920s and is
     used  by some  US states  in  criminal investigations,  as well  as by  the
     Federal government in screening people for Top Secret clearances.

     [...]   A  second  approach  to  dealing  with  deception  is  to  train  a
     machine-learning  classifier  on real  customer  behaviour.   This is  what
     credit-card fraud engines have been doing  since the late 1990s, and recent
     research has  pushed into  other fields too.  [...] Dealing  with deception
     using statistical machine learning rather than physiological monitoring may
     also be felt to intrude less into privacy.

*** Passwords
    The management of passwords gives an instructive context in which usability,
    applied psychology and security meet. Passwords have been one of the biggest
    practical problems  facing security engineers  since perhaps the  1970s.  In
    fact, as the  usability researcher Angela Sasse puts it,  it’s hard to think
    of a worse authentication mechanism than passwords, given what we know about
    human memory: people can’t remember infrequently-used or frequently- changed
    items; we  can’t forget on  demand; recall  is harder than  recognition; and
    non-meaningful words are more difficult.

    [...] Developing a  full-feature password management system can be  a lot of
    work, and  providing support for password  recovery also costs money  (a few
    years  ago,  the  UK  phone  company  BT  had  two  hundred  prople  in  its
    password-reset  centre).  So  outsourcing  'identity  management'  can  make
    business sense.  In addition,  intrusion detection works  best at  scale: if
    someone uses  my gmail  password in  an Internet cafe  in Peru  while Google
    knows I'm in  Scotland, they send an SMS  to my phone to check,  and a small
    website can't do that.

**** Social-engineering attacks
     Careful organisations communicate security context  in various ways to help
     staff avoid  making mistakes. The  NSA, for example, had  different colored
     internal and external  telephones, and when an external phone  in a room is
     off-hook, classified  material can't even  be discussed  in the room  - let
     alone on the phone.

**** Customer education
     After phishing  became a real  threat to  online banking in  the mid-2000s,
     banks  tried to  train  their customers  to look  for  certain features  in
     websites. This  has been partly risk  reduction, but partly risk  dumping -
     seeing  to  it  that  customers  that  don't  understand  or  can't  follow
     instructions can  be held  resposible for the  resulting loss.  The general
     pattern  has been  that as  soon as  customers are  trained to  follow some
     particular rule, the  phishermen exploit this, as the reasons  for the rule
     are not adequately explained.

**** Can you deny service?
     There are  basically three  ways to  deal with  password guessing  when you
     detect it: lockout, throttling, and protective monitoring. Banks may freeze
     your card  after three wrong PINs;  but if they freeze  your online account
     after  three   bad  password  attempts   they  open  themselves  up   to  a
     denial-of-service   attack.    Service   can   also   fail   by   accident;
     poorly-configured   systems   can   generate  repeat   fails   with   stale
     credentials.  So many  commercial websites  nowadays use  throttling rather
     than lockout. In a  military system, you might not want  even that, in case
     an enemy who gets access to the network  could jam it with a flood of false
     logon attempts. In this case,  protective monitoring might be the preferred
     option, with a plan to abandon rate-limiting if need be in a crisis.

**** Attacks on password storage

***** One-way encryption
      Such incidents taught people to protect passwords by encrypting them using
      a one-way algorithm, an innovation due  to Roger Needham and Mike Guy. The
      password, when entered, is passed through  a one-way function and the user
      is logged on  only if it matches a previously  stored value. However, it's
      often implemented wrong.  The right way to  do it is to  generate a random
      key, historically known in this context  as a /salt/; combine the password
      with the salt using a slow, cryptographically strong one-way function; and
      store both the salt and the hash.

**** Absolute limits
     If you have confidence in the cryptographic algorithms and operating-system
     security mechanisms that protect passwords,  then the probability of a suc-
     cessful password guessing attack is a function of the entropy of passwords,
     if they  are centrally  assigned, and  the psychology  of users  if they’re
     allowed to  choose them.  Military sysadmins often  prefer to  issue random
     passwords,  so  the  probability  of   password  guessing  attacks  can  be
     managed. For  example, if L  is the maximum  password lifetime, R  is login
     attempt rate,  S is the  size of the  password space, then  the probability
     that a password  can be guessed in  its lifetime is P =  LR∕S, according to
     the US Department of Defense password management guideline.

**** Will we ever get rid of passwords?
     Passwords are annoying, so many people  have discussed getting rid of them,
     and the move from laptops to phones gives us a chance. The proliferation of
     IoT devices that don't have keyboards will  force us to do without them for
     some  purposes.  A  handful  of  firms  have  tried  to  get  rid  of  them
     completely.  One  example   is  the  online  bank   Monzo,  which  operates
     exclusively  via an  app. They  leave it  up to  the customer  whether they
     protect  their phone  using  a fingerprint,  a  pattern lock,  a  PIN or  a
     password. However they still use email  to prompt people to upgrade, and to
     authenticate  people who  buy a  new  phone, so  account takeover  involves
     either  phone takeover,  or  guessing  a password  or  a password  recovery
     question. The most popular app that  uses SMS to authenticate rather than a
     password may be  WhatsApp. I expect that this will  become more widespread;
     so we'll see  more attacks based on phone takeover,  from SIM swaps through
     Android malware,  SS7 and RCS  hacking, to  simple physical theft.  In such
     cases, recovery often means an email  loop, making your email password more
     critical  than ever  -  or phoning  a  call centre  and  telling them  your
     mother's maiden name. So things may change less than they seem.

     Criterias against an authentication system can be evaluated:

     + resilience to theft
     + resilience to physical observation
     + resilience to guessing
     + resilience to malware and other internal compromise
     + resilience to leaks from other verifiers
     + resilience to phishing and to targeted impersonation
     + ease of use
     + ease of learning
     + whether you need to carry something extra
     + error rate
     + ease of recovery
     + cost per user
     + whether it's an open design that anyone can use

     [...] Firms that  are targets of state-level attackers, such  as Google and
     Microsoft, now  give authentication tokens of  some kind or another  to all
     their staff.

*** CAPTCHAs
    'Completely  Automated  Public Turing  Test  to  Tell Computers  and  Humans
    Apart'. [...] The idea is that  people can solve such problems easily, while
    computers find them hard.
