#+title: Studies
#+author: Me
#+date: 2021-07-31

Org is a  highly flexible structured plain text  file format, composed
of a  few simple, yet versatile,  structures - constructed to  be both
simple enough for the novice and powerful enough for the expert.

+ Tools I want to get better during August 2021:

---
08-2021:

- [x] F#
- [x] Emacs
- [x] Git

* TODO F# docs

** Functions

   Functions are the fundamental unit of program execution in any programming language. In F#,
   all functions are considered values; in fact, they are known as /function values/.

   #+BEGIN_SRC fsharp
     // Non-recursive function definition
     let [inline] function-name parameter-list [: return-type] = function-body
     // Recursive function definition
     let rec function-name parameter-list = recursive-function body
   #+END_SRC

   *Scope*

   At any level of scope other than module scope, it is not an error to reuse a value or function
   name. If you reuse a name, the name declared later shadows the name declared earlier. However,
   at the top level scope in a module, names must be unique.

   *Partial application of arguments*

   If you supply fewer than the specified number of arguments, you create a new function that
   expects the remaining arguments. This method of handling arguments is referred to as /currying/
   and is characteristic of functional programming languages like F#.

   #+BEGIN_SRC fsharp
     let cylinderVolume (radius: float) (length: float) : float =
	 let pi = 3.14159
	 length * pi * radius * radius
     let smallPipeRadius = 2.0
     let bigPipeRadius = 3.0
     let smallPipeVolume = cylinderVolume smallPipeRadius
     let bigPipeVolume = cylinderVolume bigPipeRadius
   #+END_SRC

   Because functions are values, they can be used as arguments to other functions or in other
   contexts where values are used.

   *Lambda expressions*

   A /lambda expression/ in an unnamed function.

   #+BEGIN_SRC fsharp
     let apply (fn: int -> int) value = fn value
     let lambdaFun = fun x -> x + 1
     apply lambdaFun 2
     // result: 3
   #+END_SRC

   *Function composition and pipelining*

   The composition of two functions *fn1* and *fn2* is another function that represents the
   application of *fn1* followed the application of *fn2*.

   #+BEGIN_SRC fsharp
     let fn1 x = x + 1
     let fn2 y = y * 2
     let compfn = fn1 >> fn2
     let result = compfn 100
     // result: 202
   #+END_SRC

   Pipelining enables function calls to be chained together as successive operations. Pipelining
   works as follows:

   #+BEGIN_SRC fsharp
     let result = 100 |> fn1 |> fn2
     // result: 202
   #+END_SRC

   *Recursive functions*

   For some recursive functions, it is necessary to refactor a more "pure" definition to one that
   is [[https://cs.stackexchange.com/questions/6230/what-is-tail-recursion][tail recursive]]. This prevents unnecessary recomputations.

** Classes

   [[https://docs.microsoft.com/en-us/dotnet/fsharp/language-reference/classes][F# docs - Classes]]

   Classes represent the fundamental description of .NET object types; the class is the primary type
   concept that supports object-oriented programming in F#.

* DONE Learning F# (book)
  CLOSED: [2021-08-15 dom 10:02]

The F# compiler -- which is open source -- compiles your programs into IL, which means that you
can use F# code from any .NET compatible language such as C#; and run it on Mono, .NET Core, or the
.NET framework on windows.

[<EntryPoint>] -> This syntax defines a .NET attribute.

| I'll not continue reading this book since its content is not well explained. |

* TODO Emacs docs

  Ref: [[https://orgmode.org/guide][ORG COMPACT GUIDE]]

** TABLES
  Org comes with a fast and intuitive table editor. Spreadsheet-link calculations are supported in
  connection with the Emacs Calc package. [[https://www.gnu.org/software/emacs/manual/html_node/calc/index.html#Top][GNU Emacs calculator]].

  A table is re-aligned automatically each time you press /TAB/ or /RET/ or /C-c C-c/ inside the
  table. /TAB/ also moves to the next field (/RET/ to the next row) and creates new table rows at
  the end of the table or before horizontal lines. The indentation of the table is set by the first
  line.

  #+BEGIN_SRC org
    |Name|Phone|Age|
    |-
    
    + /TAB/
    
    =
    
    | Name | Phone | Age |
    |------+-------+-----|
    |      |       |     |
  #+END_SRC

  When typing text into a field, Org treats /DEL/, /Backspace/, and all character keys in a special
  way, so that inserting and deleting avoids shifting other fields. Also, when typing immediately after
  point was moved into a new field with /TAB/, the field is automatically made blank.

  *Some commands:*

  /C-c C-c/
    Re-align the table without moving point.

  /TAB/
    Re-align the table, move to the next field. Creates a new row if necessary.

  /S-TAB/
    Re-align, move to previous field.

  /RET/
    Re-align the table and move down to next row. Creates a new row if necessary.

  /S-UP/
  /S-DOWN/
  /S-LEFT/
  /S-RIGHT/
    Move a cell up, down, left, and right by swapping with adjacent cell.

  /M-LEFT, M-RIGHT/
    Move the current column left/right.

  /M-S-LEFT/
    Kill the current column.

  /M-S-RIGHT/
    Insert a new column to the left of point position.

  /M-UP, M-DOWN/
    Move the current row up/down.

  /M-S-UP/
    Kill the current row or horizontal line.

  /M-S-DOWN/
    Insert a new row above the current row. With a prefix argument, the line is created below the
    current one.

  /C-c -/
    Insert a horizontal line below current row. With a prefix argument, the line is created above the
    current line.

  /C-c RET/
    Insert a horizontal line below current row, and move the point into the row below that line.

  /C-c ^/
    Sort the table lines in the region. The position of point indicates the column to be used for
    sorting, and the range of lines is the range between the nearest horizontal separator lines, or
    the entire table.
  
** HYPERLINKS

  Org provides links inside a file, external links to other files, and much more. Also, Org
  recognizes plain URIs, possibly wrapped within angle brackets, and activate them as clickable
  links. The general link format, however, looks like this.
   
  #+BEGIN_SRC org
    [[LINK][DESCRIPTION]]
    
    [[LINK]]
  #+END_SRC

  *Some commands:*

  /C-c C-l/
    Insert a link. This prompts for a link to be inserted into the buffer. You can just type a link,
    or use history keys /UP/ and /DOWN/ to access stored links. You will be prompted for the
    description part of the link.
  
  /C-c C-l/
    Edit the invisible /LINK/ part, with the point on the link.

  /C-c C-o/
    Open link at point.

  /C-c &/
    Jump back to a recorded position. A position is recorded by the commands following internal links,
    and by /C-c %/. Using this command several times in direct succession moves through a ring of
    previously recorded positions.

** /TODO ITEMS/

   Org mode does not require TODO lists to live in separate documents. Instead, TODO items are part
   of a notes file, because they usually come up while taking notes.

   Basically, any headline becomes a TODO item when it starts with the word 'TODO':

   #+BEGIN_SRC org
     **** TODO Write letter to Sam Fortune
   #+END_SRC

   You can use TODO keywords to indicate @emph{sequential} working progress states. [[https://orgmode.org/guide/Multi_002dstate-Workflow.html#Multi_002dstate-Workflow][Doc link]].

   *Checkboxes:*

   Every item in a plain list can be made into a checkbox by starting it with the string '[ ]'.
   Checkboxes are not included into the global TODO list, so they are often great to split a task
   into a number of simple steps.

   *Some commands:*

   /C-c C-t/
     Rotate the TODO state of the current item among
     (unmarked) -> TODO -> DONE -> (unmarked)

   /S-RIGHT/
   /S-LEFT/
     Select the following/preceding TODO state, similar to cycling

   /C-c / t/
     View TODO items in a sparse tree. Folds the entire buffer, but shows all TODO items-with not-DONE
     state-and the headings hierarchy above them.

   /M-x org-agenda t/
     Show the global TODO list. Collects the TODO items (with not-DONE states) from all agenda files
     into a single buffer.

   /S-M-RET/
     Insert a new TODO entry below the current one.

* TODO SAFE

  The SAFE acronym is made up of four separate components:

  * Saturn -> for back-end services in F#

      The Saturn library builds on top of the solid foundation of both the F#-friendly Giraffe and the
      high performance, rock-solid ASP.NET Core web server to provide a set of optional abstractions
      which make configuring web applications and constructing complex routes extremely easy to
      achieve.

      Saturn can host RESTful API endpoints, drive static websites or server-generated content, all
      inside an easy-to-learn functional programming model.

  * Azure -> as a hosting platform plus associated platform services
  * Fable -> for running F# in the web browser

      Is an  F# to Javascript  compiler, designed to  produce readable
    and standard code. Fable allows you to create applications for the
    browser  written  entirely in  F#,  whilst  also allowing  you  to
    interact with native Javascript as needed.
  
  * Elmish -> for client-side user interfaces

* DONE [DB] Optimistic vs pessimistic lock
  CLOSED:              [2021-08-22             dom              10:53]
  [[https://stackoverflow.com/questions/129329/optimistic-vs-pessimistic-locking/129397#129397][Discussion
  on StackOverflow]]

  - Optimistic locking:

    1. Read a record (with version number) ->
    2. Check that the version hasn't changed ->
    3.1 Write the data (uncorrupted hash);
    3.2 Abort the transaction and the user need to restart it (corrupted hash);

    This strategy is most applicable to high volume systems and three-tier architectures where
    you do not necessarily maintain a connection to the database for your session. In this
    situation the client cannot actually maintain database locks as the connections are taken
    from a pool and you may not be using the same connection from one access to the next.

  - Pessimistic locking:

    1. Lock the record for your exclusive use until you have finished it.

    It has much better integrity with than optimistic locking but requires you to be careful with
    your application design to avoid _deadlocks_. To use pessimistic locking you need either a
    direct connection to the database (as would typically be the case in a two tier client server
    application) or an externally available transaction ID that can be used independently of the
    connection.
    
* DONE QEMU + NixOS
  CLOSED: [2021-08-26 qui 21:23]
  With the help of Magueta.

** DONE [[https://www.computerhope.com/jargon/b/bios.htm][BIOS]]
   CLOSED: [2021-08-26 qui 19:08]

   BIOS means short for *Basic Input/Output System*, is a *ROM (Read Only Memory)* chip found on
   motherboards that allows you to access and set up your computer system at the most basic
   level.

   The BIOS includes instructions on how to load basic computer hardware. It also includes a test
   referred to as a POST (Power-On Self-Test) that helps verify the computer meets requirements
   to boot up properly. If the computer does not pass the POST, you head a combination of beeps
   indicating what is malfunctioning in the computer.

   1. POST - Test the computer hardware and make sure no errors exist before loading the OS.
   2. Bootstrap loader - Locate the OS. If a capable OS is located, the BIOS will pass control
      to it.
   3. BIOS drivers - Low-level drivers that give the computer basic operational control over
      your computer's hardware.
   4. BIOS setup or CMOS setup - Configuration program that allows you to configure hardware
      settings including system settings, such as date, time, and computer passwords.

   The BIOS does things like configure the keyboard, mouse, and other hardware, set the system clock, 
   test the memory, and so on. Then it look for a drive and loads the boot loader on the drive, which
   is either an MBR or GPT partition table.
** DONE UEFI
   CLOSED: [2021-08-26 qui 19:08]

   UEFI stands for Unified Extensible Firmware Interface. It is a publicly available specification
   that defines a software interface between an operating system and platform firmware.
   
   UEFI replaces the legacy BIOS firmware interface originally present in all IBM pc's, with most
   UEFI firmware implementations providing support for legacy BIOS services. UEFI can support
   remote diagnostics and repair of computers, even with no operating system installed.
** DONE [[https://www.redhat.com/en/topics/virtualization/what-is-KVM][KVM]]
   CLOSED: [2021-08-26 qui 19:08]

   KVM stands for Kernel-based Virtual Machine. It's an open source virtualization technology
   built into Linux. Specifically, KVM lets you turn Linux into a hypervisor that allows a host
   machine to run multiple, isolated virtual environments called guests or virtual machines (VMs).

   *KVM is part of Linux.*
** DONE [[https://www.qemu.org/][QEMU]]
   CLOSED: [2021-08-26 qui 19:08]

  [[https://qemu-project.gitlab.io/qemu/][Link to the docs.]]

  According to the site, QEMU is a generic and open source machine emulator and virtualizer.

  1. Emulator -

     Hardware or software that enables one computer system (called the host) to behave
     like another computer system (called the guest). An emulator typically enables the host
     system to run software or use peripheral devices designed for the guest system. Emulation
     refers to the ability of a computer program in an electronic device to emulate (or imitate)
     another program or device.
  2. Virtualizer -

     Virtualization means a variety of technologies for managing computer resources
     by providing a software interface, known as an "abstraction layer", between the software
     (operating system and applications) and the hardware. Virtualization turns "physical" RAM
     and storage into "logical" resources.

     2.1. Hardware virtualization -

     This is what most computer people are referring to when they talk about virtualization. It
     partitions the computer's RAM into separate and isolated "virtual machines" (VMs) simulating
     multiple computers within one physical computer. Hardware virtualization enables multiple
     copies of the same or different operating systems to run in the computer and prevents the OS
     and its application in one VM from interfering with the OS and applications in another VM.

     2.2. Network and storage virtualization -

     In a network, virtualization consolidates multiple devices into a logical view so they can
     be managed from a single console. Virtualization also enables multiple storage devices to be
     accessed the same way no matter their type or location.

     2.3. Application virtualization -

     Application virtualization refers to several techniques that make
     running applications protected, flexible and easy to manage.
  
     2.4. OS virtualization -

     Under the control of one operating system, a server is split into
     "containers" that each handle an application.
  
  With this tool it's possible to:
  - Run operating systems for any machine, on any supported architechture.
    It provides a virtual model of an entire machine (CPU, memory and emulated devices) to run
    a guest OS.
  - Run programs for another Linux/BSD target, on any supported architechture.
  - Run KVM and Xen virtual machines with near native performance.

  [[https://www.youtube.com/watch?v=AAfFewePE7c&ab_channel=DenshiVideo][[YouTube - QEMU: A proper guide!]​]]
** DONE Partition information
   CLOSED: [2021-08-26 qui 21:22]

   In this section I'll be sharing other necessary topics to
   understand the complete installation of the NixOS image.
*** Swap memory

    [[https://www.enterprisestorageforum.com/hardware/what-is-memory-swapping/][Ref link.]]

    Memory swapping is a computer techonology that enables an
    operating system to provide more memory to a running application
    or process than is available in physical *random access memory*
    (RAM). When the physical system memory is exhausted, the operating
    system can opt to make use of memory swapping techniques to get
    additional memory.

    Memory swapping works by making use of virtual memory and storage
    space in an approach that provides additional resources when
    required. In short, this additional memory enables the computer to
    run faster and crunch data better.

    With memory swapping, the operating system makes use of storage
    disk space to provide functional equivalent of memory storage
    space.

    The process of memory swapping is managed by an operating system
    or by a virtual machine hypervisor.

    Advantages of memory swapping:

    - More memory: memory swapping is a critical component of memory
management, enabling an operating system to handle requests that would
otherwise overwhelm a system.

    - Continuous operations: swap file memory can be written to disk
in a continuous manner, enabling faster lookup times for operations.

    - System optimization: application processes of lesser importance
and demand can be relegated to swap space, saving the higher
performance physical memory for higher value operations.

    Limitations of memory swapping:

    - Performance: disk storage space, when called up by memory
swapping, does not offer the same performance as physical RAM for
process execution.

    - Disk limitations: swap files are reliant on the stabiity and
availability of storage media, which might not be as stable as system
memory.

    - Capacity: memory swapping is limited by the available swap space
that has been allocated by an operating system or hypervisor.
*** LVM volumes

    In Linux, Logical Volume Manager (LVM) is a device mapper
    framework that provides logical volume management for the Linux
    kernel. Most modern Linux distributions are LVM-aware to the point
    of being able to have their root file systems on a logical volume.
*** Systemd

    [[https://en.wikipedia.org/wiki/Systemd][Reference link.]]

    systemd is a software suite that provides an array of system
    components for Linux operating systems. Its main aim is to unify
    service configuration and behavior across Linux distributions;
    systemd's primary component is a "system and service manager" - an
    init system used to bootstrap user space and manage user
    processes. It also provides replacements for various daemons and
    utilities, including device management, login management, network
    connection management, and event logging. The name systemd adheres
    to the Unix convention of naming daemons by appending the letter d.
*** Software RAID devices

    [[https://en.wikipedia.org/wiki/RAID][Reference link.]]

    RAID stands for "Redundant Array of Inexpensive Disks", is a data
    storage virtualization technology that combines multiple physical
    disk drive components into one or more logical units for the
    purposes of data redundancy, performance improvement, or
    both. This was in contrast to the previous concept of highly
    reliable mainframe disk drives referred to as "single large
    expensive disk" (SLED).
*** UEFI (GPT) x Legacy Boot (MBR)

    [[https://www.freecodecamp.org/news/mbr-vs-gpt-whats-the-difference-between-an-mbr-partition-and-a-gpt-partition-solved/][Reference link.]]

    The main difference between UEFI and legacy boot is that **UEFI** is the 
    latest method of booting a computer that is designed to replace BIOS 
    while the **legacy boot** is the process of booting the computer using
    BIOS firmware.

    Also, UEFI more is recommended because it includes more security features
    (with less complex code) than the legacy BIOS mode.

    GPT and MBR are related to the partition used in the OS.

    Q: So, what's a partition?

    A: Is a virtual division of a hard disk drive (HDD) or a solid state drive
    (SSD). Each partition can vary in size and typically serves a different
    function.

    In Linux there's typically a root partition (`/`), one for swap which helps
    with memory management, and large /home partition. the /home partition is
    similar to the C: partition in Windows in that it's where you install most
    of your programs and store files.

    Program to check the partitions: **GParted**.

    An overview of MBR and GPT partitions

    Before a drive can be divided into individual partitions, it needs to be
    configured to use a specific partition scheme or table.

    A partition table tells the OS how the partitions and data on the drive are
    organized. MBR stands for Master Boot Record, and is a bit of reserved space
    at the beginning of the drive that contains the information about how the
    partitions are organized. The MBR also contains code to launch the OS, and
    it's sometimes called the Boot Loader.

    GPT is an abbreviation of GUID Partition Table, and is a newer standard that's
    slowly replacing MBR. Unlike MBR partition table, GPT stores the data about
    how all the partitions are organized and how to boot the OS throughout the
    drive. That way if one partition is erased or corrupted, it's still possible
    to boot and recover some of the data.

    Some differences:

    * The maximum capacity of MBR partition tables is only about 2 TB. You can use
      a drive that's larger than 2 TB with MBR, but only the first 2 TB of the drive
      will be used. The rest of the storage on the drive will be wasted.

    * In contrast, GPT partition tables offer a maximum capacity of 9.7 ZB, where
      1 ZB = 1 billion TB.

    * MBR partition tables can have a maximum of 4 separate partitions. However,
      one of those partitions can be configured to be an extended partition, which
      is a partition that can be split up into an 23 additional partitions. So the
      absolute maximum number of partitions an MBR partition table can have is 26
      partitions.

    * GPT partition tables allow for up to 128 separate partitions, which is more
      than enough for most real world applications.

    * As MBR is older, it's usually paired with older Legacy BIOS systems, while
      GPT is found on newer UEFI systems. This means that MBR partitions have
      better software and hardware compatibility, though GPT is starting to catch
      up.
** DONE Steps
   CLOSED: [2021-08-26 qui 21:23]
  
  Choose an interface for the system
  - i3wm gaps
  - dwm -> built with C code
  - install the minimum system and install the interface later

  Download the minimal image and configure it to use with QEMU.

  #+BEGIN_SRC bash
    # download the minimal image:
    $ wget https://channels.nixos.org/nixos-21.05/latest-nixos-minimal-x86_64-linux.iso
    # it will download a file named: latest-nixos-minimal-x86_64-linux.iso
    
    # config the image
    # cmd template -> qemu-img create -f qcow2 NOME.img XG
    $ qemu-img create -f qcow2 nixos-test.img 20G
    # command used to create, convert and modify disk images
    # -f:
    #   Stands for format option. qcow2 stands for copy on write 2nd generation.
    
    
    # bootstrap the machine
    # cmd template -> qemu-system-x86_64 -boot d -cdrom image.iso -m 512 -hda mydisk.img
    $ qemu-system-x86_64 -enable-kvm -boot d \
    $ -cdrom latest-nixos-minimal-x86_64-linux.iso \
    $ -m 2G -cpu host -smp 2 -hda nixos-test.img
    # command used to boot an image
    # to get the help use the -h flag
    # -enable-kvm:
    #   Enable KVM full virtualization support. This option is only available if KVM support
    #   is enabled when compiling.
    # -boot
    #   Specify boot order drives as a string of drive letters. Valid drive letters depend on
    #   the target architechture. The x86 PC uses: a, b (floppy 1 and 2), c (first hard disk)
    #   d (first CD-ROM), n-p (Etherboot from network adapter 1-4), hard disk boot is the default.
    # -cdrom
    #   Use file as CD-ROM image (you cannot use -hdc and -cdrom at the same time). You can use
    #   the host CD-ROM by using /dev/cdrom as filename.
    # -m
    #   Set the quantity of RAM.
    # -hda
    #   Use file as hard disk 0, 1, 2 or image.
    
    # start the vm after closing it
    $ qemu-system-x86_64 -enable-kvm -boot d \
    $ -m 2G -cpu host -smp 2 -hda nixos-test.img
  #+END_SRC

  Follow the installation steps provided by the docs. [[https://nixos.org/manual/nixos/stable/index.html#sec-installation][Link here.]]
  
  Some useful keyboard commands:

  - /Ctrl-alt-g/ -> free the mouse from inside the image.
  - /Ctrl-alt-f/ -> toggle switch fullscreen.
* DONE Basic database concepts
  CLOSED: [2021-09-07 ter 19:48]

- Language used: _Tutorial D_

** Why is faster to do the computations in the database instead of doing with F#?

1. We don't pay the network price.
2. Database runs a series of optimized operations to work with data, generally a
*B-tree* and indexes. When we manipulate data inside F# we are loading everything into
a big chunk of memory. In the best case we will be using O(n) memory where n is the
size of the data.

** Intro

#+BEGIN_SRC bash
  | id | H1 | H2 | H3 | # HEADING
  | ~  | ~  | ~  | ~  | # row content = tuple
  | ~  | ~  | ~  | ~  |
  | ~  | ~  | ~  | ~  |
  | ~  | ~  | ~  | ~  |
  | ~  | ~  | ~  | ~  |

  # table degree = no. of heading (ex.: 4)
  # cardinality = no. of tuples (ex.: 4)
#+END_SRC

Assumptions:

  * Relations never contains duplicate tuples (mathematical set).
  * The tuples of a relation are unordered, top to bottom.
  * The attributes (heading) of a relation are unordered, left to right.
  * Relations (not tables) are always normalized (in 1NF - normal for). Which 
    just means that every tuple in the body conforms to the heading.
  * To perform a join operation the tables must be joinable, i.e.: relations are
    joinable if and only if attributes with the same name are of the same type.
  * Cartesian product is a special case of JOIN. Also, intersect is a special case
    of JOIN as well.

An aggregate operator is not, in general, a relational operator (because the
result usually isn't a relation). It's an operator that derives a single value
from the "aggregate" (i.e., the set or bag) of values of some attribute of some
relation - or, for COUNT, from the entire relation.

  * Integrity constraint

An integrity constraint is, loosely, a boolean expression that must evaluate to
TRUE. This is one of the most important properties of a database. With this we can
trust that the result we are reading from this tool is correct.

System can't enforce truth, can only enforce consistency.

  * Predicates

Heading corresponds to a predicate (truth valued function). Predicates are related
to the understanding of tables in a database.

  * RELATIONS vs. TYPES: TYPES are sets of things we can talk about; RELATIONS are
    (true) statements about those things!

    1. Types and relations are both NECESSARY
    2. They're not the same thing
    3. They're SUFFICIENT (as well as necessary)

A DB (plus its operators) is a logical system!!!

** The relational model:

1. An open ended set of types (including in particular type BOOLEAN)
2. A relational type generator and an intended interpretation for relations of
   types generated thereby
3. Facilities for defining relation variables of such generated relation types
4. A relational assignment operation for assigning relation values to such
   relation variables
5. A relationally complete (but otherwise open ended) set of generic operators
   for deriving relation values from other relation values

** Transactions

A transaction is a piece of program execution: a logical unit of work. Begins by
executing a BEGIN TRANSACTION statement. Ends by executing either a COMMIT or
a ROLLBACK statement.

All database updates (actually database reads too) must be done within the context
of some transaction.

The ACID properties:

1. Atomicity: Transactions are all or nothing. Logical unit of work.
2. Consistency: Transactions transform a consistent state of the DB into another
   consistent state, without necessarily preserving consistency at all intermediate
   points. Logical unit of integrity.
3. Isolation: Any given transaction's update are concealed from all other
   transactions until the given transaction commits. Logical unit of concurrency.
4. Durability: Once a transaction commits, its updates survive in the DB, even
   if there's a subsequent system crash. Logical unit of recovery.

** Database design

Design theory is part of the relational theory in general, but it isn't part of the
relational model as such... It's a separate theory that's built on top of that model.

Recall:

  * Relations are always normalized (i.e., in "1NF"). Which just means every tuple in 
    the body conforms to the heading.
* TODO F# async model
  Produce  a  presentation  about   the  F#  async  model.   Scheduled
  presentation date: 2021-09-16.

References:

[1] - [[https://docs.microsoft.com/en-us/dotnet/fsharp/tutorials/asynchronous-and-concurrent-programming/async#how-to-work-with-net-async-and-taskt][Async programming in F#]] - Very good
[2] - [[https://devblogs.microsoft.com/pfxteam/executioncontext-vs-synchronizationcontext/][ExecutionContext vs SynchronizationContext]] - Too complex
[3] - [[https://docs.microsoft.com/en-us/archive/msdn-magazine/2013/march/async-await-best-practices-in-asynchronous-programming][Async/Await - Best Practices in Asynchronous Programming]] - Too C#/old
[4] - [[https://fsharpforfunandprofit.com/posts/concurrency-async-and-parallel/][Asynchronous programming]] - Very good
[5] - [[https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/async-padl-revised-v2.pdf][The F# Asynchronous Programming Model]] - Very good but with some complex parts
[6] - [[https://github.com/rspeele/TaskBuilder.fs][TaskBuilder.fs docs]] - Very good
[7] - [[http://tomasp.net/blog/csharp-fsharp-async-intro.aspx/][Asynchronous C# and F# (I.): Simultaneous introduction]]
[8] - [[http://tomasp.net/blog/async-csharp-differences.aspx/][Asynchronous C# and F# (II.): How do they differ?]]
[9] - [[http://tomasp.net/blog/async-compilation-internals.aspx/][Asynchronous C# and F# (III.): How does it work?]]

** Theory

*** Definitions:

+ Concurrency: when multiple computations execute in sequential time periods.
+ Parallelism: when multiple computations or several parts of a single computation
  run at exactly the same time.
+ Asynchrony: when one or more computations can execute separately from the main
  program flow. Asynchrony is independent of the utilization of multiple threads.

[1]

*** Etymology of the word "asynchronous":

+ "a", meaning "not".
+ "synchronous", meaning "at the same time".

[1]

*** Asynchronous model within F#:

Since OS threads are expensive  because they allocate system resources
and  large   stacks,  while   lightweight  threading  alone   is  less
interoperable because it slows down  in CPU-intensive native code. And
asynchronous programming  using callbacks  is difficult,  the approach
adopted  by F#  since 2007  is to  add an  asynchronous modality  as a
first-class  feature  to  a  general purpose  language  design,  where
"modality" mens  reusing the  control flow syntax  of a  host language
with a different computational interpretation.

This modality has control constructs that are syntactically a superset
of  the core  language and  these are  given an  asynchronous semantic
interpretation. For F#, this allows  asynchronous code to be described
fluently  in   familiar  language   syntax,  without   disturbing  the
foundation  of CPU-intensive  programming  that allows  F# to  compile
efficiently  to  Common   IL,  and  hence  to  native   code,  and  to
interoperate well with .NET and C libraries.

[5]

*** Use cases:

+ Presenting a server process that can service a significant number of 
  concurrent incoming requests, while minimizing the system resources 
  occupied while request processing awaits inputs from systems or services 
  external to that process.
+ Maintaining a responsive UI or main thread while concurrently progressing 
  background work.

[1]

*** Practical terms:

In practical terms,  asynchronous computations in F#  are scheduled to
execute *independently of the main program flow*.

This independent execution doesn't imply concurrency or parallelism,
nor does it imply that a computation always happens in the
background. 

In  fact, asynchronous  computations can  even execute  synchronously,
depending on  the nature  of the computation  and the  environment the
computation is executing in.

Although there  are few  garantees about when  or how  an asynchronous
computation executes,  there are some approaches  to orchestrating and
scheduling them.

Example:

#+BEGIN_SRC fsharp
let getWebPage (url: string) = 
  async {
    let req = WebRequest.Create url
    let! resp = req.AsyncGetResponse()
    let stream = resp.GetResponseStream()
    let reader = new StreamReader(stream)
    return! reader.AsyncReadToEnd() }
#+END_SRC

The above example uses several asynchronous operations provided by the
F# library,  namely *AsyncGetResponse*  and *AsyncReadToEnd*.  Both of
these are  I/O primitives  that are  typically used  at the  leaves of
asynchronous operations.

The key  facet of an  asynchronous I/O primitive  is that it  does not
block  an  OS  thread  while  executing,  but  instead  schedules  the
continuation of the asynchronous computation as a callback in response
to an event.

[1, 5]

*** Core concepts:

In  F#,  asynchronous  programming   is  centered  around  three  core
concepts:

+ The ~Async<'T>~ type, which represents a composable asynchronous computation.
+ The ~Async~ module functions, which let you schedule asynchronous work, compose
  the asynchronous computations, and transform asynchronous results.
+ The ~async { }~ computation expression, which provides a convenient syntax for
  building and controlling asynchronous computations. All expressions of the form
  ~async {...}~ are of the type ~Async<T>~ for some ~T~.

[1, 5]

Example:

#+BEGIN_SRC fsharp
  open System
  open System.IO

  // string -> Async<unit>
  let printTotalFileBytes path =
    async {
      let! bytes = 
        File.ReadAllBytesAsync(path)
	|> Async.AwaitTask
      let fileName = Path.GetFileName(path)
      printfn $"File {fileName} has %d{bytes.Length} bytes"
    }

 [<EntryPoint>]
 let main argv =
   printTotalFileBytes "path-to-file.txt"
   |> Async.RunSynchronously

   Console.Read() |> ignore
   0
#+END_SRC

In  F#,  asynchronous   computations  can  be  thought   of  as  *Cold
tasks*. They must be explicitly  started to actually execute. This has
some advantages, as it allows you to combine and sequence asynchronous
work much more easily than in C# or Visual Basic.

[1]

*** Grammar of asynchronous expressions:

[[/home/gajo/org/imgs/fsharp-async-grammar.png]]

[5]

*** Asynchronous execution:

Because  F#  asynchronous computations  are  a  specification of  work
rather than a  representation of work that is  already executing, they
must be explicitly started with a starting function.

+ Parallel
+ Sequential

[[https://docs.microsoft.com/en-us/dotnet/fsharp/tutorials/asynchronous-and-concurrent-programming/async#important-async-module-functions][Async starting methods]]

[1]

*** Exception Handling and Resource Compensation:

Without  a language  support, the  exception handling  in asynchronous
computation is  extremely difficult. With language  support it becomes
simple: the  ~try ... with~  and ~try  ... finally~ constructs  can be
used in async expressions in the natural way:

#+BEGIN_SRC fsharp
async { 
  try
    let! primary = getWebPage "https://primary.server.com"
    return primary.Length
  with e ->
    let! backup = getWebPage "https://backup.server.com"
    return backup.Length
}
#+END_SRC

Here,  a failure  anywhere in  the  download from  the primary  server
results in  the execution of  the exception handler and  download from
the backup server.

+ Definition:

~Deterministic resource disposal~ is a language construct that ensures
that resources  (such as file  handles) are disposed  at the end  of a
lexical scope. In F#  this is the construct *use val  = expr in expr*,
translated to *let val = expr  in try expr finally val.Dispose()*. The
resource *val* is freed on exit from the lexical scope.

Resource  cleanup  in  asynchronous  code is  also  difficult  without
language support. Many OO design  patterns for async programming use a
"state" object to  hold the state elements of  a composed asynchronous
computation,  but this  is non-compositional.  With language  support,
state becomes implied by closure, and resource cleanup becomes simple.

[5]

*** Cancellation

A cancellation mechanism  allows computations to be sent  a message to
"stop" execution, e.g. "thread abort" in .NET. Cancellation mechanisms
are  always a  difficult  topic in  imperative programming  languages,
because  compiled,  efficient  native code  often  exhibits  extremely
subtle properties  when pre-emptively  cancelled at  arbitrary machine
instructions.  However, for  asynchronous computations  we can  assume
that primitive asynchronous operations are the norm (e.g. waiting on a
network   request),  and   it  is   reasonable  to   support  reliable
cancellation  at these  operations. Furthermore,  it is  reasonable to
implicitly  support  cooperative  cancellation at  specific  syntactic
points, and additionally through user-defined cancellation checks.

F# async supports  the implicit propagation of  a ~cancellation token~
through   the  execution   of   an   asynchronous  computation.   Each
cancellation  token is  derived  from a  ~cancellation capability~  (a
*CancellationTokenSource*   in  .NET),   used  to   set  the   overall
cancellation condition. A  cancellation token can be given  to lots of
functions.

#+BEGIN_SRC fsharp
let capability = new CancellationTokenSource()
let tasks = Async.Parallel [ getWebPage "https://google.com"
                             getWebPage "https://bing.com" ]

// Start the work
Async.Start (tasks, cancellationToken = capability.Token)
// Ok, the work is in progress, now cancel it...
capability.Cancel()
#+END_SRC

Cancellation is checked  at each I/O primitive,  subject to underlying
.NET library and O/S support, and before the execution of each return,
let!, use!,  try/with, try/finally, do!  and async { ...  } construct,
and before  each iteration of an  asynchronous while or for  loop. For
getWebPage this means cancellation can occur at several places. But it
cannot  occur  during core-language  code  (e.g.  expressions such  as
library calls, executed for side-effects), and it cannot occur in such
a  way that  the  resource-reclamation  implied by  the  use and  use!
expression  constructs is  skipped.  Cancellation  is not  necessarily
immediately effective: in  a multi-core or distributed  setting it may
take arbitrarily long to propagate the cancellation message.

[5]

*** The main differences between _Task_ and _Async_ CE:

This is related to the interoperate  with .NET. C# and the majority of
.NET libraries use the ~Task<TResult>~  and ~Task~ types as their core
abstractions rather  than ~Async<'T>~,  so you  must cross  a boundary
between these two approaches to asynchrony.

You   can  use   *Async.AwaitTask*  to   await  a   .NET  asynchronous
computation,  or  the  *Async.StartAsTask*  to  pass  an  asynchronous
computation to a .NET caller.

You can  use the *Async.AwaitTask*  that accepts  a Task as  input and
this custom  function to start and  await Task types from  an F# async
computation.

#+BEGIN_SRC fsharp
  // Async<unit> -> Task
  let startTaskFromAsyncUnit (comp: Async<unit>) =
    Async.StartAsTask comp :> Task
#+END_SRC

In practice  I have seem most  of the code using  the Task computation
expression  provided  by  the  TaskBuilder.fs to  handle  .NET  ~Task~
s. According  to its docs,  F#'s ~Async~ behaves a  little differently
from ~Task~, which can be confusing  if you're used to the latter. So,
the goal  of the ~task~ computation  expression builder is to  let you
write asynchronous blocks that behave  just like ~async~ methods in C#
do.

[1, 6]

*** Relationship to multi-threading:

  1. There is no affinity between an asynchronous computation and a thread, 
     unless explicitly started  on the current thread.  For example, a
     computation may actually run on its caller's thread, depending on
     the nature of  the work. A computation could  also "jump" between
     threads, borrowing them  for a small amount of time  to do useful
     work in between periods of "waiting" (such as when a network call
     is in transit).

     Although  F# provides  some  abilities to  start an  asynchronous
     computation  on the  current  thread (or  explicitly  not on  the
     current thread),  asynchrony generally  is not associated  with a
     particular threading strategy.

     Each  running computation  in  .NET implicitly  has  access to  a
     synchronization  context, which  for  our purposes  is  a way  of
     taking a function closure and running it "somewhere". We use this
     to execute asynchronous callbacks.

  2. Asynchronous programming in F# is not an abstraction for multi-
     threading.

[1, 5]


** Examples

*** How to deal with asynchronous code using callbacks

+ Asynchronous programming using callbacks is difficult.

[5]

+ How to deal with asynchronous code using modern approachs
+ How the context influence the asynchronous (thread)
* DONE Terminal commands
  CLOSED: [2021-09-05 dom 20:43]
  
- [x] find
GNU  find   searches  the   directory  tree   rooted  at   each  given
starting-point by evaluating the given  expression from left to right,
according to  the rules of  precedence (see section  OPERATORS), until
the outcome is known (the left  hand side is false for and operations,
true for or), at which point find  moves on to the next file name.  If
no starting-point is specified, `.' is assumed.

- [x] xargs
xargs reads items from the  standard input, delimited by blanks (which
can be  protected with double  or single quotes  or a back‐  slash) or
newlines, and executes the command  (default is /bin/echo) one or more
times with any initial-arguments followed  by items read from standard
input.  Blank lines on the stan‐ dard input are ignored.

- [x] sed
Sed is a stream editor.  A stream editor is used to perform basic text
transformations on an input stream (a  file or input from a pipeline).
While in some  ways similar to an editor which  permits scripted edits
(such as ed), sed  works by making only one pass  over the in‐ put(s),
and is consequently more efficient.  But it is sed's ability to filter
text  in a  pipeline which  particularly distinguishes  it from  other
types of editors.

- [x] cut
Print selected parts of lines from each FILE to standard output.
With no FILE, or when FILE is -, read standard input.

- [x] tr
Translate,  squeeze, and/or  delete  characters  from standard  input,
writing to standard output.

- [x] sort
Write sorted concatenation of all FILE(s) to standard output.
With no FILE, or when FILE is -, read standard input.
* DONE Postgres lock
  CLOSED: [2021-09-11 sáb 12:17]

[[https://www.citusdata.com/blog/2018/02/15/when-postgresql-blocks/][PostgreSQL rocks, except when it blocks: Understanding locks]]
[[https://www.citusdata.com/blog/2018/02/22/seven-tips-for-dealing-with-postgres-locks/][When Postgres blocks: 7 tips for dealing with locks]]
[[https://skyvia.com/gallery/list-of-all-queries-currently-running-on-postgresql][List of all queries currently running on PostgreSQL]]
[[https://medium.com/little-programming-joys/finding-and-killing-long-running-queries-on-postgres-7c4f0449e86d][Finding and killing long running queries on PostgreSQL]]

** Check PG locks

Sometimes you notice a command is taking awfully long, but the process
is not actually doing anything. In that case it might be waiting for a
lock and you should have a look at *pg_locks*.

To see which query is waiting for a  lock, the PG wiki has a [[https://wiki.postgresql.org/wiki/Lock_Monitoring][number of
useful queries for displaying lock information]].

Get all the information from PG:

#+BEGIN_SRC sql
  SELECT * FROM pg_stat_activity;
#+END_SRC

** Do's and don'ts

1. Never add a column with a default value
   Adding a  column takes a very  aggressive lock on the  table, which
   blocks  read  and write.  If  you  add  a  column with  a  default,
   PostgreSQL will rewrite the whole table  to fill in the default for
   every row, which  can take hours on large tables.  In the meantime,
   all queries will block, so your database will be unavailable.

   #+BEGIN_SRC sql
     -- Don't do this:
     ALTER TABLE items ADD COLUMN last_update timestamptz DEFAULT now();

     -- Do this instead:
     ALTER TABLE items ADD COLUMN last_update timestamptz;
     UPDATE items SET last_update = now();

     -- A better approach would be to update using small batches
     do {
       numRowsUpdated = executeUpdate(
         "UPDATE items SET last_update = ? " +
	 "WHERE ctid IN (SELECT ctid FROM items WHERE last_update IS NULL LIMIT 5000)",
	 now);
     } while (numRowsUpdate > 0);
   #+END_SRC

2. Beware of lock queues, use lock timeouts
   Every lock in PG has a queue. If a transaction B tries to acquire a
   lock that is already held by  transaction A with a conflicting lock
   level,  then  transaction  B  will  wait in  the  lock  queue.  Now
   something interesting  happens: if another transaction  C comes in,
   then it will not  only have to check for conflict  with A, but also
   with transaction B, and any other transaction in the lock queue.

   This means that even if  your DDL command (Data Definition Language
   commands consists  of the SQL commands  that can be used  to define
   database operations) can  run very quickly, it might be  in a queue
   for a  long time waiting  for queries  to finish, and  queries that
   start after it will be blocked behind it.

   #+BEGIN_SRC sql
     -- When you can have long-running SELECT queries on a table, don't do this:
     ALTER TABLE items ADD COLUMN last_update timestamptz;

     -- Instead, do this:
     SET lock_timeout TO '2s'
     ALTER TABLE items ADD COLUMN last_update timestamptz;
   #+END_SRC

   By setting *lock_timeout*, the DDL command  will fail if it ends up
   waiting  for a  lock, and  thus blocking  queries for  more than  2
   seconds. The downside is that your *ALTER TABLE* might not succeed,
   but you can try again later.

   You  may want  to  query  *pg_stat_activity* to  see  if there  are
   long-running queries before starting the DDL command.

3. Create indexes CONCURRENTLY
   Creating an index  on a large dataset can take  hours or even days,
   and the  regular *CREATE INDEX*  command blocks all writes  for the
   duration of the command. While it doesn't block *SELECT* s, this is
   still pretty bad and there's a better way:

   #+BEGIN_SRC sql
     -- Don't do this:
     -- blocks all writes
     CREATE INDEX items_value_idx ON items USING GIN (value jsonb_path_ops);

     -- Instead do this:
     -- only block other DDL
     CREATE INDEX CONCURRENTLY items_value_idx ON items USING GIN (value jsonb_path_ops);
   #+END_SRC

   Creating an index  concurrently does have a  downside. If something
   goes  wrong  it  does  not  roll  back  and  leaves  an  unfinished
   ("invalid") index behind. If that  happens, don't worry, simply run
   *DROP  INDEX CONCURRENTLY  items_value_idx*  and try  to create  it
   again.

4. Take aggressive locks as late as possible
   When you need to run a  command that acquires aggressive locks on a
   table, try to do it as late in the transaction as possible to allow
   queries to continue for as long as possible.

   #+BEGIN_SRC sql
     -- For example, if yu want to completely replace the contents of a table:

     -- Don't do this:
     BEGIN;
     -- reads and writes blocked from here:
     TRUNCATE items;
     -- long-running operation:
     \COPY items from 'newdata.csv' WITH CSV
     COMMIT;

     -- Instead load the data into a new table and then replace the old table:
     BEGIN;
     CREATE TABLE items_new (LIKE items INCLUDING ALL);
     -- long-running operation:
     \COPY items_new FROM 'newdata.csv' WITH CSV
     -- reads and writes blocked from here:
     DROP TABLE items;
     ALTER TABLE items_new RENAME TO items;
     COMMIT;
   #+END_SRC

   There is  one problem, we didn't  block writes from the  start, and
   the old *items* table might have changed by the time we drop it. To
   prevent that, we  can explicitly take a lock the  table that blocks
   writes, but not reads:

   #+BEGIN_SRC sql
     BEGIN;
     LOCK items IN EXCLUSIVE MODE;
     ...
   #+END_SRC

5. Adding a primary key with minimal locking
   Postgres makes  it very easy to  create a primary key  using *ALTER
   TABLE*, but  while the index  for the  primary key is  being built,
   which can take a long time if  the table is large, all queries will
   be blocked.

   #+BEGIN_SRC sql
     -- Don't do this
     -- blocks queries for a long time
     ALTER TABLE items ADD PRIMARY KEY (id);

     -- Do this instead:
     -- takes a long time, but doesn't block queries
     CREATE UNIQUE INDEX CONCURRENTLY items_pk ON items (id);
     -- blocks queries, but only very briefly
     ALTER TABLE items ADD CONSTRAINT items_pk PRIMARY KEY USING INDEX items_pk;
   #+END_SRC

   By breaking down primary key creation into two steps, it has almost
   not impact on the user.

6. Never VACUUM FULL
   The PG user experience can  be a little surprising sometimes. While
   *VACUUM FULL* sounds  like something you want to do  clear the dust
   of your db, a more appropriate command would have been:

   #+BEGIN_SRC sql
     PLEASE FREEZE MY DATABASE FOR HOURS;
   #+END_SRC

   *VACUUM FULL*  rewrites the  entire table to  disk, which  can take
   hours of days,  and blocks all queries while doing  it. While there
   are some  valid use cases for  *VACUUM FULL*, such as  a table that
   used to be big, but is now small and still takes up a lot of space,
   it is probably not your use case.

   While  you should  aim to  tune  your autovacuum  settings and  use
   indexes to make your queries fast, you may occasionally want to run
   *VACUUM*, but NOT *VACUUM FULL*.

7. Avoid deadlocks by ordering commands
   If you've been using PG for a while, chances are you've seen errors
   like:

   #+BEGIN_SRC sql
     ERROR:  deadlock detected
     DETAIL:  Process 13661 waits for ShareLock on transaction 45942; blocked by process 13483.
     Process 13483 waits for ShareLock on transaction 45937; blocked by process 13661.
   #+END_SRC

   This happens when  concurrent transactions take the same  lock in a
   different order. For example:

   #+BEGIN_SRC sql
     -- one transaction issues the following command:
     BEGIN;
     UPDATE items SET counter = counter + 1 WHERE key = 'hello'; -- grabs lock on hello
     UPDATE items SET counter = counter + 1 WHERE key = 'world'; -- blocks waiting for world
     END;

     -- simultaneously, another transaction might be issuing the same commands, but in a different order:
     BEGIN
     UPDATE items SET counter = counter + 1 WHERE key = 'world'; -- grabs lock on world
     UPDATE items SET counter = counter + 1 WHERE key = 'hello';  -- blocks waiting for hello
     END; 
   #+END_SRC

   If these  transaction blocks  run simultaneously, chances  are that
   they get  stuck waiting for each  other and would never  finish. PG
   will recognise this situation after a  second or so and will cancel
   one of  the transactions  to let  the other  one finish.  When this
   happen, you  should take a look  at your application to  see if you
   can  make  transactions  always  follow the  same  order.  If  both
   transactions  first modify  *hello*, then  *world*, then  the first
   transaction will block the second one on the *hello* lock before it
   can grab any other locks.
** Finding and killng long running queries on PG

In order to find them you can use the following query:

#+BEGIN_SRC sql
  SELECT
    pid,
    now() - pg_stat_activity.query_start AS duration,
    query,
    state
  FROM pg_stat_activity
  WHERE (now() - pg_stat_activity.query_start) > interval '5 minutes';
#+END_SRC

If the  state is  idle you don't  need to worry  about it,  but active
queries may be the reason behind low performances on your database.

In order to cancel the long running queries you should execute:

#+BEGIN_SRC sql
  SELECT pg_cancel_backend(__pid__);
#+END_SRC

Where   the   pid   parameter   is   the   value   returned   in   the
*pg_stat_activity*.  It may  take  a  few seconds  to  stop the  query
entirely using the *pg_cancel_backend* command.

If you think that the process is stuck you can kill it by running:

#+BEGIN_SRC sql
  SELECT pg_terminate_backend(__pid__);
#+END_SRC

*Be careful with that!* pg_terminate_backend is  the kill -9 in PG. It
 will terminate the  entire process which can lead to  a full database
 restart in order to recover consistency.
