:PROPERTIES:
:ID:       ac1af467-8d9d-436b-ba1c-2c57251aa93b
:END:
#+title: [Azure] AI-900
#+date: [2022-02-14 seg 18:25]

* Virtual Training Day: AI Fundamentals

On 02-14-2022 I have participated in a session of the Microsoft Azure Virtual
Training Day focused in the AI Fundamentals services.

+ Instructor: Tycho Juta.
+ His LinkedIn: https://linkedin.com/in/tychojuta.

Principles of responsible AI:
- Fairness
- Reliability & safety
- Privacy & security
- Inclusiveness
- Transparency
- Accountability

https://aka.ms/learn-artificial-intelligence

** What is AI?

Simply put, AI is the creation of software that imitates human behaviors and
capabilities. Key elements include:

- Machine learning;
- Anomaly detection;
- Computer vision;
- Natural language processing;
- Conversational AI.

** Azure Machine Learning

"Creating predictive models by finding relationships in data."
    
- Regression
- Classification
- Clusterization

** Azure machine learning

What? Is a cloud service that you can use to train and manage machine learning
models.

How? Math and statistics. Classification (predicting categories or
classes). Regression (predicting numeric values). Time series forecasting
(predicting numeric values at a future point in time).

The automated machine learning capability in Azure Machine Learning supports
supervised machine learning models - in other words, models for which the
training data includes known label values.

*** Compute targets overview

+ Compute Instances:

  Development workstations that data scientists can use to work with data and
  models.

+ Compute Clusters:

  Scalable clusters of virtual machines for on-demand processing of experiment
  code.

+ Inference Clusters:

  Deployment targets for predictive services that use your trained models.

+ Attached Compute:

  Links to existing Azure compute resources, such as Virtual Machines or Azure
  Databricks clusters.

** Voucher information
  
- How do I get my exam voucher?

You will receive an email with instructions after the event concludes on how to
access your exam discount for a single attempt of AI-900 (https://aka.ms/ai900)
that will be linked automatically with your Microsoft Certification Dashboard
(https://docs.microsoft.com/en-us/learn/certifications/) in 5 business days. The
exam discount is valid for 90 days. See FAQ for further info
-https://query.prod.cms.rt.microsoft.com/cms/api/am/binary/RWG1g3.

- Any tip on how to succeed in AI-900 exam?

Go through the information at https://aka.ms/aifunpath.

** Some useful links shared in presentation

  + Responsible AI - https://www.microsoft.com/ai/responsible-ai

  + Cards Demo - https://aka.ms/hci-demo

  + Learn more - https://aka.ms/learn-artificial-intelligence

  + Machine Learning Demo - https://aka.ms/No-code-automl

  + Computer Vision Demo - https://aidemos.microsoft.com/computer-vision

  + Image Classification Demo -
  https://aka.ms/learn-image-classification

  + Learn more - https://aka.ms/explore-computer-vision

  + Natural Language Processing Demo -
  https://aidemos.microsoft.com/text-analytics

  + Text Analytics Demo - https://aidemos.microsoft.com/luis/demo

  + Language Understanding Demo - https://aka.ms/learn-luis

  + Using a Bot Demo -
  https://www.microsoft.com/en-us/research/project/health-bot/

  + Learn more - https://aka.ms/explore-bots

  + QnA Maker Link - https://www.qnamaker.ai/

  + Learn more - https://aka.ms/explore-nlp

  + You can find demos here - https://aidemos.microsoft.com/

* Azure Computer Vision

- Custom vision:
  
  A dedicated resource for the custom vision service, which can be training, a
  prediction, or both resources.
  
- Cognitive services:
  
  A general cognitive services resource that includes Custom Vision along with
  many other cognitive services. You can use this type of resource for training,
  prediction, or both.

** Uses of image classification

- Product identification:

  Performing visual searches for specific products in online searches or even,
  in-store using a mobile device.

- Disaster investigation:

  Identifying key infrastructure for major disaster preparation efforts. For
  example, identifying bridges and roads in aerial images can help disaster
  relief teams plan ahead in regions that are not well mapped.

- Medical diagnosis:

  Evaluating images from X-ray or MRI devices could quickly classify specific
  issues found as cancerous tumors, or many other medical conditions related to
  medical imaging diagnosis.

Most modern image classification solutions are based on deep learning techniques
that make use of convolutional neural networks (CNNs) to uncover patterns in the
pixels that correspond to particular classes. Training an effective CNN is a
complex task that requires considerable expertise in data science and machine
learning.

** Object detection

   Is a form of machine learning based computer vision in which a model is
   trained to recognize individual types of objects in an image, and to identify
   their location in the image.

*** Usage example

    - Checking for building safety:

      Evaluating the safety of a building by analyzing footage of its interior
      for the fire extinguishers or other emergency equipment.

    - Driving assistance:

      Creating software for self-driving cars or vehicles with lane assist
      capabilities. The software can detect whether there is a car in another
      lane, and whether the driver's car is within its own lanes.

    - Detecting tumors:

      Medical imaging such as an MRI or x-rays that can detect known objects for
      medical diagnosis.

** Face service

   Face detection, analysis, and recognition is an important capability for
   artificial intelligence solutions. The Face cognitive service in Azure makes
   it easy integrate these capabilities into your applications.

*** Facial detection
   
    Face detection involves identifying regions of an image that contain a human
    face, typically by returning a bounding box coordinates that form a
    rectangle around the face.

*** Facial analysis

    Detect facial landmarks (nose, eyes, eyebrows, lips, etc), to train a
    machine learning model from which you can infer information about a person,
    such as their perceived emotional state.

*** Facial recognition

    Identify known individuals from their facial features.

*** Microsoft Azure services

    + Computer vision:
      Offers face detection and some basic face analysis, such as determining
      age.

    + Video indexer:
      Detect and identify faces in a video.

    + Face:
      Offers pre-built algorithms that can detect, recognize and analyze faces.

** Optical character recognition (OCR)

   Optical character recognition (OCR) enables artificial intelligence (AI)
   systems to read text in images, enabling applications to extract information
   from photographs, scanned documents, and other sources of digitized text.

   This is related to:

   + Process written or printed text

   The basic foundation of processing printed text is optical character
   recognition (OCR), in which a model can be trained to recognize individual
   shapes as letters, numerals, punctuation, or other elements of text. Much of
   the early work on implementing this kind of capability was performed by
   postal services to support automatic sorting of mail based on postal
   codes. Since then, the state-of-the-art for reading text has moved on, and
   it's now possible to build models that can detect printed or handwritten text
   in an image and read it line-by-line or even word-by-word.

   At the other end of the scale, there is machine reading comprehension (MRC),
   in which AI systems not only reads the text characters, but can use a
   semantic model to interpret what the text is about.

*** Uses of OCR

    + note taking;
    + digitizing forms, such as medical records or historical documents;
    + scanning printed or handwritten checks for bank deposits.

*** Azure resources for computer vision

    + Computer Vision:

      A specific resource for the Computer Vision service. Use this resource
      type if you don't intend to use any other cognitive services, or if you
      want to track utilization and costs for your Computer Vision resource
      separately.

    + Cognitive Services:

      A general cognitive services resource that includes Computer Vision along
      with many other cognitive services; such as Text Analytics, Translator
      Text, and others. Use this resource if you plan to use multiple cognitive
      services and want to simplify administration and development.

*** Knowledge check

    1. You want to extract text from images and then use the Text Analytics
       service to analyze the text. You want developers to require only one key
       and endpoint to access all of your services. What kind of resource
       should you create in your Azure subscription?

       A: Cognitive Services. This resource support both Computer Vision for text
       extraction, and Text Analytics for text analysis.

    2. You plan to use the Computer Vision service to read text in a large PDF
       document. Which API should you use?

       A: The Read API. This API is better suited for larger images but it runs
       asynchronously so it will not block your application while it is running.

** Analyze receipts with the Form Recognizer service

   A common problem in many organizations is the need to process receipt or
   invoice data. For example, a company might require expense claims to be
   submitted electronically with scanned receipts, or invoices might need to be
   digitizes and routed to the correct accounts department. Typically after a
   document is scanned, someone will still need to manually enter the extracted
   text into a database.

   Increasingly, organizations with large volumes of receipt and invoices to
   process are looking for artificial inteliggence (AI) solutions that can not
   only extract the text data from receipts, but also inteliggently interpret
   the information they contain.

   Azure's *Form Recognizer* service can solve this issue by digitizing fields
   from forms using optical character recognition (OCR).

*** Knowledge check

    1. You plan to use the Form Recognizer pre-built receipt model. Which kind
       of Azure resource should you create?

       A: Form Recognizer or Cognitive Services resource.

    2. You are using the Form Recognizer service to analyze receipts that you
       have scanned into JPG format images. What is the maximum file size of
       JPG file that you can submit to the pre-built receipt model?

       A: 50 MB

* Natural Language Processing
  
  Natural language processing supports applications that can see, hear, speak
  with, and understand users. Using text analytics, translation, and language
  understanding services, Microsoft Azure makes it easy to build applications
  that support natural language.

** Text Analysis with the Language service

   + Text mining;
   + Text analysis:
     + Sentiment analysis;
     + Key phrase extraction;
     + Named entity recognition;
     + Language detection.

*** What is text analysis?

    It is a process where computer program (AI algorithm) evaluate different
    aspects of a phrase, in order to gain insights into the content of that
    text.

*** What are the most common techniques used to build NPL algorithms?

    + Statistical analysis of terms used in the text.

      Removing common "stop words" (words like "the" or "a", which reveal little
      semantic information about the text).

      Performing frequency analysis of the remaining words (counting how often
      each word appears) can provide clues about the main subject of the text.

    + Extending frequency analysis to multi-term phrases.

      This technique is commonly known as N-grams (a two-word phrase is a
      bi-gram, a three-word is a tri-gram, and so on).

    + Applying stemming or lemmatization algorithms to normalize words before
      counting them.

      For example, so that words like "power", "powered", and "powerful" are
      interpreted as being the same word.

    + Applying linguistic structure rules to analyse sentences.

      For example, breaking down sentences into tree-like structures such as a
      noun phrase, which itself contains nouns, verbs, adjectives, and so on.

    + Encoding words or terms as numeric features.

      This can be used to train a machine learning model. For example, this
      model can classify a text document based on the terms it contains. This
      technique is often used to perform sentiment analysis, in which a document
      is classified as positive or negative.

    + Creating vectorized models.

      Those models capture semantic relationships between words by assigning
      them to locations in n-dimensional space.

      This modeling technique might, for example, assign values to the words
      "flower" and "plant" that locate them close to one another, while
      "skateboard" might be given a value that positions it much further away.

*** Microsoft Azure - Language service

    This service was created to simplify application development by using
    pre-trained models that can:

    + Determine the language of a document or text (for example, French or
      English).
    + Sentiment analysis on text to determine positive or negative sentiment.
    + Key phrases extraction.
    + Identify and categorize entities in the text.

      For example: people, places, organizations, or even everyday items such as
      dates, times, quantities, and so on.

*** How can someone use the Language service?

    You must provision an appropriate resource in your Azure subscription. You
    can choose to provision either of the following types of resources:

    + A Language resource:

      Choose this resource type if you only plan to use natural language
      processing services, or if you want to manage access and billing for the
      resource separately from other services.

    + A Cognitive Services resource:

      Choose this resource type if you plan to use the language service in
      combination with other cognitive services, and you want to manage access
      and billing for these services together.

*** Knowledge check

    1. You want to use the Language service to determine the key talking
       points in a text document. Which featue of the service should you use?

       A) Sentiment analysis.
       B) Key phrase extraction. x
       C) Entity detection.

    2. You use the Language service to perform sentiment analysis on a
       document, and a score of 0.99 is returned. What does this score indicate
       about the document sentiment?

       A) The document is positive. x
       B) The document is neutral.
       C) The document is negative.

    3. When might you see NaN returned for a score in Language Detection?

       A) When the score calculated by the service is outside the range of
       0 to 1.
       B) When the predominant language in the text is mixed with other
       languages.
       C) When the language is ambiguous. x

** Recognize and synthesize speech

   Increasingly, we expect artificial intelligence (AI) solutions to accept
   vocal commands and provide spoken responses. [...] To enable this kind of
   interaction, the AI system must support two capabilities:

   + Speech recognition - detect and interpret spoken input.
   + Speech synthesis - generate spoken output.

*** Speech recognition

    Is concerned with taking the spoken word and converting it into data that
    can be processed - often by transcribing it into a text
    representation. [...] Speech patterns are analyzed in the audio to determine
    recognizable patterns that are mapped to words. To accomplish this feat, the
    software typically uses multiple types of models, including:

    + Accoustic model:

      Converts the audio signal into phonemes (representations of specific
      sounds).

    + Language model:

      Maps phonemes to words, usually using a statistical algorithm that
      predicts the most probable sequence of words based on the phonemes.

*** Speech synthesis

    This is in many respects the reverse of speech recognition. It is concerned
    with vocalizing data, usually by converting text to speech. A speech
    synthesis solution typically requires the following information:

    + The text to be spoken.
    + The voice to be used to vocalize the speech.

*** Microsoft Azure products

    + Speech-to-Text API.
    + Text-to-Speech API.

    One could use the standalone service (Speech resource), or a more general
    one (Cognitive Services).

*** Knowledge check

    1. You plan to build an application that uses the Speech service to
       transcribe audio recordings of phone calls into text, and then submits
       the transcribed text to the Text Analytics service to extract key
       phrases. You want to manage access and billing for the application
       services in a single Azure resource. Which type of Azure resource
       should you create?

       A) Speech
       B) Text Analytics
       C) Cognitive Services x

    2. You want to use the Speech service to build an application that reads
       incoming email message subjects aloud. Which API should you use?

       A) Speech-to-Text
       B) Text-to-Speech x
       C) Translate

** Translate text and speech

   + Literal translation:

     Each word is translated to the corresponding word in the target language.

   Artificial intelligence systems must be able to understand, not only the
   words, but also the /semantic/ context in which they are used.

*** Microsoft services

    + Translator Text: text-to-text translation.
    + Speech: speech-to-text and speech-to-speech translation.
    + Cognitive Services: both services and more.

*** Knowledge check

    1. You are developing an application that must take English input from a
       microphone and generate a real-time text-based transcription in Hindi.
       Which service should you use?

       A) Translator Text
       B) Speech x
       C) Text Analytics

    2. You need to use the Translator Text service to translate an email
       message from Spanish into both English and French. What is the most
       efficient way to accomplish this goal?

       A) Make a single call to the service; specifying a "from" language
       of "es", a "to" language of "en", and another "to" language of "fr".
       x
       B) Make a single call to the service; specifying a "from" language
       of "es", and a "to" language of "en-fr".
       C) Make two calls to the service; one with a "from" language of "es"
       and a "to" language of "en", and another with a "from" language of
       "es" and a "to" language of "fr".

** Create a language model with Conversational Language Understanding

*** Knowledge check

    1. You need to provision an Azure resource that will be used to author
       a new Language Understanding application. What kind of resource should
       you create?

       A) Custom Language service
       B) Language service x
       C) Cognitive Services

    2. You are authoring a Conversational Language Understanding application
       to support an international clock. You want users to be able to ask for
       the current time in a specified city, for example "What is the time in
       London?". What should you do?

       A) Define a "city" entity and a "GetTime" intent with utterances that
       indicate the city intent. x
       B) Create an intent for each city, each with an utterance that asks for
       the time in that city.
       C) Add the utterance "What time is in city" to "None" intent.

    3. You have published your Conversational Language Understanding application.
       What information does a client application developer need to get
       predictions from it?

       A) The endpoint and key for the application's prediction resource. X
       B) The endpoint and key for the application's authoring resource.
       C) The Azure credentials of the user who published the Language
       Understanding application.
