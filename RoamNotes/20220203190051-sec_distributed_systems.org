:PROPERTIES:
:ID:       8994353b-0aaf-441f-b88d-ae46f37714f0
:END:
#+title: [Security] Distributed systems
#+date: [2022-02-03 qui 19:00]

Chapter 7 of the Security Engineering book that I'm reading as a coaching
exercise.

** Concurrency

Processes are called /concurrent/ if they can run at the same time, and this is
essential for performance; modern computers have many cores and run many
programs at a time, typically for many users.

Concurrency is hard to do robustly, especially when processes can act on the
same data. Processes may use old data; they can make inconsistent updates; the
order of updates may or may not matter; the system might deadlock; the data in
different systems might never converge to consistent values; and when it's
important to make things happen in the right order, or even to know the exact
time, this can be trickier than you might think. The issues go up and down the
entire stack.

[...] Concurrency control in the real world is also a security issue. Like
access control, it is needed to prevent users interfering with each other,
whether accidentally or on purpose. And concurrency problems can occur at many
levels in a system, from the hardware right up to the business logic.

**** Why systems are becoming more concurrent?

+ Scale (serve more users)
+ Device complexity (more devices are able to use robust computer processors)
+ Interaction complexity (projects depending on other projects to run)

*** Using old data versus paying to propagate state

We've already covered two kinds of concurrency problems:

+ Replay attacks on protocols:
  Where an attacker manages to pass out-of-date credentials.

+ Race conditions:
  Where two programs can race to update some security state.

[...] Preventing some attacks isn't always economical, as propagating changes in
security state can be expensive.

**** Card fraud example

Credit and debit cards got popular in the 1970s, and so did fraus. To deal with
it banking industry had to manage lists of /hot cards/ (whether stolen or
abused) and this scenario got worse in 1980s as card networks went
international.

It isn't possible to keep a complete hot card list in every merchant terminal,
since it requires the instant transmition of data to tens of milions of devices,
and even if we tried to verify all transactions with the bank that issued the
card, we'd be unable to use cards in places with no network (remote villages and
on airplanes).

To cope with those problems, most terminals are built to accept low cost
transactions. Merchant terminals are allowed to process transactions up to a
certain limit (the /floor limit/) offline; larger transactions need online
verification with the merchant's bank, which will know all the local hot cards
plus foreign cards that are being actively abused.

Experience taught that a more centralised approach can work better for bad
terminals. FICO observed that criminals take a handful of stolen cards to a cash
machine and try them out one by one; they maintain a list of the 40 ATMs
worldwide that have been used most recently for attempted fraud, and banks that
subscribe to their service decline all transactions at those machines - which
become unusable by those banks' cards for maybe half an hour. Most thieves don't
understand this and just throw them away.

*** Locking to prevent inconsistent updates

When people work concurrently on a document, they may use a version control
system to ensure that only one eprson has write access at any time to any given
part of it, or at least to warn of contention and flag up any inconsistent
edits. /Locking/ is one general way to manage contention for resources such as
filesystems and to make conflicting updates less likely. Another approach is
/callback/; a server may keep a list of all those clients which rely on it for
security state and notify them when the state changes.

** Fault tolerance and failure recovery

Failure recovery is often the most important aspect of security engineering, yet
it is one of the most neglected. [...] As you read through this book, you'll see
that many other applications, from burglar alarms through electronic warfare to
protecting a company from DDoS attacks, are fundamentally about
availability. Fault tolerance and failure recovery are often the core of the
security engineer's job.

Classical fault tolerance is usually based on redudancy, fortified using
mechanism such as logs and locking.

+ Mean-time-before-failure (MTBF)
+ Mean-time-to-repair (MTTR)

*** Interaction with fault tolerance

We can constrain the failure rate in a number of ways. The two most obvious are
by using /redudancy/ and /fail-stop processes/.

+ /fail-stop-processes/:

  Process error-correction information along with data, and stop when an
  inconsistency is detected.

  Example: bank transactions processing will typically stop if an out-of-balance
  condition is detected after a processing task.

There was pioneering work on a /fault-tolerant multiprocessor/ (FTMP) in the
1970s, where both tecniques we mentioned before are used together. This initial
study was driven by the Space Shuttle project, where people explored which
components should be redundant and the associated design trade-offs around where
the error detection takes places and how closely everything is
synchronised. Such research ended up driving the design of fault-tolerant
processors used in various submarines and spacecraft, as well as architectures
used by Boeing and Airbus, along with some payment machine companies.

** Naming

Naming is tricky in our current global scenario.

*** The Needham naming principles

People building distributed systems soon realised that naming gets complex
quickly, and the lessons are set out in a classic article by Needham. Here are
his ten principles:

1. The function of names is to facilitate sharing.
2. The naming information may not be all in one place, and so resolving names
   brings all the general problems of a distributed system.
3. It is bad to assume that only so many names will be needed.

   The shortage of IP addresses, which motivated the development of IP version 6
   (IPv6), is well enough discussed.

4. Global names buy you less than you think.
5. Names imply commitments, so keep the scheme flexible enough to cope with
   organisational changes.
6. Names may double as access tickets, or capabilities.
7. Things are made much simpler if an incorrect name is obvious.
8. Consistency is hard, and is often fudged. If directories are replicated, then
   you may find yourself unable to read, or to write, depending on whether too
   many or too few directories are available.
9. Don't get too smart. Phone numbers are much more robust than computer
   addresses.
10. Some names are bound early, others not; and in general it is a bad thing
    to bind early if you can avoid it.
