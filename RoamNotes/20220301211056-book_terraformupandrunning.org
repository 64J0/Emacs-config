:PROPERTIES:
:ID:       a3c36c62-c2b3-407a-ae33-25e2cef65089
:END:
#+title: [Book] Terraform Up And Running
#+date: [2022-03-01 ter 21:10]
#+edition: 2nd
#+bibliography: "../bib/Terraform_Up_Running.bibtex"

+ What is Terraform?

Terraform is an open source tool created by HashiCorp that allows you to define
your infrastructure as code using a simple, declarative language and to deploy
and manage that infrastructure across a variety of public cloud providers (e.g.,
AWS, Azure, GCP, DigitalOcean) and private cloud and virtualization platforms
(e.g., OpenStack, VMWare) using a few commands.

Terraform is an open source tool created by Hashicorp and written in the Go
programming language.

+ Where to find this book codes? [[https://github.com/brikis98/terraform-up-and-running-code][Book's github repository]].
+ [[https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs][Azure resources]].

* 1 - Why Terraform

  [...] Software isn't done until you deliver it to the user.

  Software delivery consists of all of the work you need to do to make the code
  available to a customer, such as running that code on production servers,
  making the code resilient to outages and traffic spikes, and protecting the
  code from attackers.

  Some tools to keep an eye on:

  + Chef
  + Puppet
  + Terraform
  + Docker

  DevOps definition adopted by this book author:

  + The goal of DevOps is to make software delivery vastly more efficient.

  Instead of multiday merge nightmares, you integrate code continuously and
  always keep it in a deployable state. Instead of deploying code once per
  month, you can deploy code dozens of times per day, or even after every single
  commit. And instead of constant outages and downtime, you build resilient,
  self-healing systems and use monitoring and alerting to catch problems that
  can't be resolved automatically.

** IAC (Infrastructure As Code)

   The idea behind IAC is that you write and execute code to define, deploy,
   update, and destroy your infrastructure. [...] In fact, a key insight of
   DevOps is that you can manage almost everything in code, including servers,
   databases, networks, log files, application configuration, documentation,
   automated tests, deployment processes, and so on.

   There are five broad categories of IAC tools that I'll write some notes next.

*** Ad Hoc Scripts

    This is the most straighforward approach to automate anything. You take
    whatever task you were doing manually, break it down into discrete steps,
    use your favorite scripting language (e.g., Bash, Ruby, Python) to define
    each of those steps in code, and execute that script on your server.

*** Configuration Management Tools

    Chef, Puppet, Ansible, and SaltStack are all configuration management tools,
    which means that they are designed to install and manage software on
    existing servers.

*** Server Templating Tools

    An alternative to configuration management that has been growing in
    popularity recently are server templating tools such as Docker, Packer, and
    Vagrant. Instead of launching a bunch of server and configuring them by
    running the same code on each one, the idea behind server templating tools
    is to create an image of the server that captures a fully self-contained
    "snapshot" of the operating system (OS), the software, the files, and all
    other relevant details.

*** Orchestration Tools

    For most real-world use cases, you'll need a way to do the following:

    - Deploy VMs and containers, making efficient use of your hardware.
    - Roll out updates to an existing fleet of VMs and containers using strategies
      such as rolling deployment, blue-green deployment, and canary deployment.
    - Monitor the health of your VMs and containers and automatically replace
      unhealthy ones (auto healing).
    - Scale the number of VMs and containers up or down in response to load (auto
      scaling).
    - Distribute traffic across your VMs and containers (load balancing).
    - Allows your VMs and containers to find and talk one another over the network
      (service discovery).

    Handling these tasks is the realm of orchestration tools such as Kubernetes,
    Marathon/Mesos, Amazon Elastic Container Service (Amazon ECS), Docker Swarm,
    Nomad, AKS.

*** Provisioning Tools

    Whereas configuration management, server templating, and orchestration tools
    define the code that runs on each server, provisioning tools such as
    Terraform, CloudFormation, and OpenStack Heat are responsible for creating
    the servers themselves. In fact, you can use provisioning tools to not only
    create servers, but also databases, caches, load balancers, queues,
    monitoring, subnet configurations, firewall settings, routing rules, Secure
    Sockets Layer (SSL) certificates, and almost every other aspect of your
    infrastructure.

** The benefits of IAC

   According to the 2016 State of DevOps Report, organizations that use DevOps
   practices, such as IaC, deploy 200 times more frequently, recover from
   failures 24 times faster, and have lead times that are 2,555 times lower.

* 2 - Getting Started with Terraform

  In this chapter, you're going to learn the basics of how to use Terraform.

** Deploy a Single Server

   Terraform code is written in the HashiCorp Configuration Language (HCL) in
   files with the extension /.tf/. It is a declarative language, so your goal is
   to describe the infrastructure you want, and Terraform will figure out how to
   create it.
  
   #+begin_src hcl :file main.tf
     variable "server_port" {
       description = "The port the server will use for HTTP requests"
       type        = number
       default     = 8080
     }

     output "public_ip" {
       value       = aws_instance.example.public_ip
       description = "The public IP address of the web server"
     }

     provider "aws" {
       region = "us-east-2"
     }

     # ami -> Amazon Machine Image
     # set this machine name
     # start a new http server listening in port 8080
     resource "aws_instance" "example" {
       ami           = "ami-0c55b159cbfafe1f0"
       instance_type = "t2.micro"
       vpc_security_group_ids = [aws_security_group.instance.id]

       user_data = <<-EOF
                   #!/bin/bash
                   echo "Hello, World" > index.html
                   nohup busybox httpd -f -p ${var.server_port} &
                   EOF

       tags = {
         Name = "terraform-example"
       }
     }

     # AWS does not allow any incoming or outgoing traffic from an
     # EC2 instance.
     resource "aws_security_group" "instance" {
       name = "terraform-example-instance"

       ingress {
         from_port   = var.server_port
         to_port     = var.server_port
         protocol    = "tcp"
         # CIDR blocks are a concise way to specify IP addr ranges
         cidr_blocks = ["0.0.0.0/0"]
       }
     }
   #+end_src

   [...]

   The reason to use big numbered ports to expose projects is that listening on
   any port less than 1024 requires root user privileges. This is a security
   risk, because any attacker who manages to compromise your server would get
   root privileges, too.

   [...]

   The <<-EOF and EOF are Terraform's /heredoc/ syntax, which allows you to
   create multiline strings without having to insert newline characters all over
   the place.

   [...]

   When Terraform walks your dependency tree, it creates as many resources in
   parallel as it can, which means that it can apply your changes faily
   efficiently. That's the beauty of a declarative language: you just specify
   what you want and Terraform determines the most efficient way to make it
   happen.

** Deploy a cluster of web servers

   Managing a cluster manually is a lot of work. Fortunately, you can let AWS
   take care of it for by you using an Auto Scaling Group (ASG).
   
   #+begin_src hcl :file main.tf
     variable "server_port" {
       description = "The port the server will use for HTTP requests"
       type        = number
       default     = 8080
     }

     output "public_ip" {
       value       = aws_instance.example.public_ip
       description = "The public IP address of the web server"
     }

     data "aws_vpc" "default" {
       default = true
     }

     data "aws_subnet_ids" "default" {
       vpc_id = data.aws_vpc.default.id
     }

     provider "aws" {
       region = "us-east-2"
     }

     # ami -> Amazon Machine Image
     # set this machine name
     # start a new http server listening in port 8080
     resource "aws_launch_configuration" "example" {
       ami            = "ami-0c55b159cbfafe1f0"
       instance_type  = "t2.micro"
       security_group = [aws_security_group.instance.id]

       user_data = <<-EOF
                   #!/bin/bash
                   echo "Hello, World" > index.html
                   nohup busybox httpd -f -p ${var.server_port} &
                   EOF

       # Required when using a launch configuration with an auto scaling group.
       # https://www.terraform.io/docs/providers/aws/r/launch_configuration.html
       lifecycle {
         create_before_destroy = true
       }

       tags = {
         Name = "terraform-example"
       }
     }

     resource "aws_autoscalling_group" "example" {
       launch_configuration = aws_launch_configuration.example.name
       vpc_zone_identifier  = data.aws_subnet.ids.default.ids

       min_size = 2
       max_size = 10

       tag {
         key                 = "Name"
         value               = "terraform-asg-example"
         propagate_at_launch = true
       }
     }

     # AWS does not allow any incoming or outgoing traffic from an
     # EC2 instance.
     resource "aws_security_group" "instance" {
       name = "terraform-example-instance"

       ingress {
         from_port   = var.server_port
         to_port     = var.server_port
         protocol    = "tcp"
         # CIDR blocks are a concise way to specify IP addr ranges
         cidr_blocks = ["0.0.0.0/0"]
       }
     }
   #+end_src

** Deploying a Load Balancer

   At this point, you can deploy your ASG, but you'll have a small problem: you
   now have multiple servers, each with its own IP address, but you typically
   want to give of your end users only a single IP to use. One way to solve this
   problem is to deploy a /load balancer/ to distribute traffic across your
   servers and to give all your users the IP (actually, the DNS name) of the
   load balancer. [...] Once again, you can let AWS take care of it for you,
   this time by using Amazon's /Elastic Load Balancer/ (ELB) service.

   #+begin_src hcl :file main.tf
     variable "server_port" {
       description = "The port the server will use for HTTP requests"
       type        = number
       default     = 8080
     }

     output "public_ip" {
       value       = aws_instance.example.public_ip
       description = "The public IP address of the web server"
     }

     data "aws_vpc" "default" {
       default = true
     }

     data "aws_subnet_ids" "default" {
       vpc_id = data.aws_vpc.default.id
     }

     provider "aws" {
       region = "us-east-2"
     }

     # ami -> Amazon Machine Image
     # set this machine name
     # start a new http server listening in port 8080
     resource "aws_launch_configuration" "example" {
       ami            = "ami-0c55b159cbfafe1f0"
       instance_type  = "t2.micro"
       security_group = [aws_security_group.instance.id]

       user_data = <<-EOF
                   #!/bin/bash
                   echo "Hello, World" > index.html
                   nohup busybox httpd -f -p ${var.server_port} &
                   EOF

       # Required when using a launch configuration with an auto scaling group.
       # https://www.terraform.io/docs/providers/aws/r/launch_configuration.html
       lifecycle {
         create_before_destroy = true
       }

       tags = {
         Name = "terraform-example"
       }
     }

     resource "aws_autoscalling_group" "example" {
       launch_configuration = aws_launch_configuration.example.name
       vpc_zone_identifier  = data.aws_subnet.ids.default.ids

       min_size = 2
       max_size = 10

       tag {
         key                 = "Name"
         value               = "terraform-asg-example"
         propagate_at_launch = true
       }
     }

     resource "aws_lb" "example" {
       name               = "terraform-asg-example"
       load_balancer_type = "application"
       subnets            = data.aws_subnet_ids.default.ids
       security_groups    = [aws_security_group.alb.id]
     }

     resource "aws_lb_listener" "http" {
       load_balancer_arn = aws_lb.example.arn
       port              = 80
       protocol          = "HTTP"

       # By default, return a simple 404 page
       default_action {
         type = "fixed-response"

         fixed_response {
           content_type = "text/plain"
           message_body = "404: page not found"
           status_code  = 404
         }
       }
     }

     resource "aws_security_group" "alb" {
       name = "terraform-example-alb"

       ingress {
         from_port   = 80
         to_port     = 80
         protocol    = "tcp"
         # CIDR blocks are a concise way to specify IP addr ranges
         cidr_blocks = ["0.0.0.0/0"]
       }

       # Allow all outbound requests
       egress {
         from_port = 0
         to_port = 0
         protocol = "-1"
         cidr_blocks = ["0.0.0.0/0"]
       }
     }

     resource "aws_lb_target_group" "asg" {
       name     = "terraform-asg-example"
       port     = var.server_port
       protocol = "HTTP"
       vpc_id   = data.aws_vpc.default.id

       health_check {
         path                = "/"
         protocol            = "HTTP"
         matcher             = "200"
         interval            = 15
         timeout             = 3
         healthy_threshold   = 2
         unhealthy_threshold = 2
       }
     }

     # AWS does not allow any incoming or outgoing traffic from an
     # EC2 instance.
     resource "aws_security_group" "instance" {
       name = "terraform-example-instance"

       ingress {
         from_port   = var.server_port
         to_port     = var.server_port
         protocol    = "tcp"
         # CIDR blocks are a concise way to specify IP addr ranges
         cidr_blocks = ["0.0.0.0/0"]
       }
     }
   #+end_src

* 3 - How to Manage Terraform State

  Previously when we were using Terraform to create and update resources, one
  must notice that every time we ran /terraform plan/ or /terraform apply/,
  Terraform was able to find the resources it created previously and update them
  accordingly. This is totally related to Terraform state.

  This chapter's focus are:

  + Terraform state management and locking
  + Configuration isolation (workspace and file layout)
  + Secrets management

  The reason you need to put so much thought into isolation, locking, and state
  is that infrastructure as code (IAC) has different trade-offs than normal
  coding.

  When you're writing code for a typical app, most bugs are relatively minor and
  break only a small part of a single app.

  When you're writing code that controls your infrastructure, bugs tend to be
  more severe, given that they can break all of your apps - and all of your data
  stores and your entire network topology, and just about everything else.
  
** What is Terraform State?

   Every time you run Terraform, it records information about what
   infrastructure it created in a Terraform state file (/terraform.tfstate/ file
   in the root directory the command is triggered).

   This /tfstate/ file contains a custom JSON format that records a mapping from
   the Terraform resources in your configuration files to the representation of
   those resources in the real world.

** Shared Storage for State Files

   [...] storing Terraform in version control is a bad idea for the following
   reasons:

   + Manual error
     - Easy to forget to pull down;
     - Easy to forget to push latest changes.
   + Locking
     - There must be a way to prevent two team members from running terraform
       aply on the same state file at the same time.
   + Secrets
     - All data in Terraform state files is stored in plain text. This is a
       problem because certain Terraform resources need to store sensitive
       data.

   Instead of using version control, the best way to manage shared storage for
   state files is to use Terraform's built-in support for remote backends. A
   Terraform /backend/ determines how Terraform loads and stores state. The
   default backend, which you've been using this entire time, is the local
   backend, which stores the state file on your local disk. Remote backends
   allow you to store the state file in a remote, shared store.

   A number of remote backends are supported, including:

   + Amazon S3;
   + Azure Storage;
   + Google Cloud Storage;
     ...

   To enable remote state storage with Amazon S3, the first step is to create an
   S3 bucket.

   #+begin_src hcl :file terraform-state/main.tf
     provider "aws" {
       region = "us-east-2"
     }

     # Creating S3 bucket to store terraform state
     resource "aws_s3_bucket" "terraform_state" {
       # Name of the S3 bucket (globally unique)
       bucket = "terraform-up-and-running-state"

       # Prevent accidental deletion of this S3 bucket
       lifecycle {
         prevent_destroy = true
       }

       # Enable versioning so we can see the full revision history of our
       # state files
       versioning {
         enabled = true
       }

       # Enable server-side encryption by default
       server_side_encryption_configuration {
         rule {
           apply_server_side_encryption_by_default {
             sse_algorithm = "AES256"
           }
         }
       }
     }
   #+end_src

** Isolation via File Layout

   To achieve full isolation between environments, you need to do the following:

   + Put the Terraform configuration files for each environment into a separate
     folder. For example, all of the configurations for the staging environment
     can be in a folder called stage and all the configurations for the
     production environment can be in a folder called prod.
   + Configure a different backend for each environment, using different
     authentication mechanisms and access controls (e.g., each environment
     could live in a separate AWS account with a separate S3 bucket as a
     backend).

** Secrets management

   Reading secrets from a secrets store or environment variables is a good
   practice to ensure secrets aren't stored in plain text in your code, but just
   a remainder: no matter how you read in the secret, if you pass it as an
   argument to a Terraform resource, such as aws_db_instance, that secret will
   be stored in the Terraform state file, in plain text.

   This is a known weakness of Terraform, with no effective solutions available,
   so be extra paranoid with how you store your state files (e.g., always enable
   encryption) and who can access those state files (e.g., use IAM permissions
   to lock down access to your S3 bucket)!

* 4 - How to Create Reusable Infrastructure with Terraform Modules

  Using Modules.

  Modules are the key ingredient to writing reusable, maintainable, and testable
  Terraform code.

** Module Basics

   A Terraform module is very simple: any set of Terraform configuration files
   in a folder is a module. All of the configuration you've written so far have
   technically been modules, although not particularly interesting ones, since
   you deployed them directly (the module in the current working directory is
   called the root module).

   Syntax to use a module:

   #+begin_src hcl :tangle no
     module "<NAME>" {
       source = "<SOURCE>" # path to the module config

       [CONFIG...] # one or more arguments specific to the module
     }
   #+end_src

   #+begin_src hcl :tangle no :file main.tf
     provider "aws" {
       region = "us-east-2"
     }

     module "webserver_cluster" {
       source = "../../../modules/services/webserver-cluster"
     }
   #+end_src
   
   Note that whenever you add a module to your Terraform configurations or
   modify the /source/ parameter of a module, you need to run the /init/
   command before you run /plan/ or /apply/.
   
** Module Inputs

   In Terraform, one can use input variables to define module inputs. It is just
   a matter of creating a new /variables.tf/ file inside the module.

   #+begin_src hcl :tangle no :file variables.tf
     variable "cluster_name" {
       description = "The name to use for all the cluster resources"
       type        = string
     }

     variable "db_remote_state_bucket" {
       description = "The name of the S3 bucket for the database's remote state"
       type        = string
     }

     variable "db_remote_state_key" {
       description = "The path for the database's remote state in S3"
       type        = string
     }
   #+end_src

   #+begin_src hcl :tangle no :file main.tf
     provider "aws" {
       region = "us-east-2"
     }

     module "webserver_cluster" {
       source = "../../../modules/services/webserver-cluster"

       cluster_name           = "webservers-stage"
       db_remote_state_bucket = "(YOUR_BUCKET_NAME)"
       db_remote_state_key    = "stage/data-stores/mysql/terraform.tfstate"
     }

     resource "aws_security_group" "alb" {
       name = "${var.cluster_name}-alb"

       ingress {
         from_port   = 80
         to_port     = 80
         protocol    = "tcp"
         cidr_blocks = ["0.0.0.0/0"]
       }

       egress {
         from_port   = 0
         to_port     = 0
         protocol    = "-1"
         cidr_blocks = ["0.0.0.0/0"]
       }
     }
   #+end_src

** Module Locals

   When we're creating the configuration for our services, sometimes we need to
   write multiple times the same information. Having these magical values
   hardcoded in multiple places makes the code more difficult to read and
   maintain.

   To solve this problem, you could extract values into input variables, but
   then users of your module will be able to (accidentally) override these
   values, which you might not want.

   So, instead of using input variables, you can define these as /local values/
   in a /locals/ block:

   #+begin_src hcl :tangle no
     locals {
       http_port    = 80
       any_port     = 0
       any_protocol = "-1"
       tcp_protocol = "tcp"
       all_ips      = ["0.0.0.0/0"]
     }
   #+end_src

   Local values allow you to assign a name to any Terraform expression, and to
   use that name throughout the module. These names are only visible within the
   module, so they will have no impact on other modules, and you can't override
   these values from outside of the module. To read the value of a local, you
   need to use a /local reference/, which uses the following syntax:

   #+begin_src hcl :tangle no
     local.<NAME>
   #+end_src

   Locals make your code easier to read and maintain, so use them often.
   
** Module Outputs

   In Terraform, a module also return values. Again, you do this using a
   mechanism you already know: output variables.

   #+begin_src hcl :tangle no :file outputs.fs
     output "asg_name" {
       value       = aws_autoscaling_group.example.name
       description = "The name of the Auto Scaling Group"
     }
   #+end_src

   You can access module output variables using the following syntax:

   #+begin_src hcl :tangle no
     module.<MODULE_NAME>.<OUTPUT_NAME>
   #+end_src
   
** Module Versioning

   If both your staging and production environment are pointing to the same
   module folder, as soon as you make a change in that folder, it will affect
   both environments on the very next deployment. This sorte of coupling makes
   it more difficult to test a change in staging without any chance of affecting
   production. A better approach is to create /versioned modules/ so that you
   can use one version in staging (v0.0.2) and a different version in production
   (v0.0.1).

*** Private Git Repos

    If your Terraform module is in a private Git repository, to use that repo as
    a module source, you need to give Terraform a way to authenticate to that
    Git repository. I recommend using SSH auth so that you don't need to
    hardcode the credentials for your repo in the code itself. With SSH
    authentication, each developer can create an SSH key, associate it with
    their Git user, and add it to ssh-agent, and Terraform will automatically
    use that key for authentication if you use an SSH source URL.

* 5 - Terraform Tips and Tricks

  Here are the topics covered in this chapter:

  + Loops
  + Conditionals
  + Zero-downtime deployment
  + Terraform gotchas

** Loops

   #+begin_src hcl :tangle no
     resource "aws_iam_user" "example" {
       count = 3
       name = "neo.${count.index}"
     }
   #+end_src

* Terraform commands

    How to run this?

   #+begin_src shell
     # install provider code (AWS, Azure, GCP, etc)
     # download and update modules
     # will save it in .terraform folder
     # one could add this folder to the gitignore
     $ terraform init # this command is idempotent

     # see what Terraform will do before actually making changes
     $ terraform plan # sanity check

     # create the instance
     $ terraform apply

     # show the dependency graph for the operation
     # output is in a graph description lang called DOT
     $ terraform graph

     # see just the output of a configuration
     $ terraform output

     # destroy services
     # WARNING: there's no undo for this command
     $ terraform destroy

     # show which workspace you're in
     $ terraform workspace show
     # create and switch to a new workspace
     $ terraform workspace new example1
     # list possible workspaces
     $ terraform workspace list
     # switch to a different workspace
     $ terraform workspace select example1
   #+end_src

   What are the files that we should put in the gitignore?

   #+begin_src txt
     .terraform
     *.tfstate
     *.tfstate.backup
   #+end_src

