:PROPERTIES:
:ID:       a3c36c62-c2b3-407a-ae33-25e2cef65089
:END:
#+title: [Book] Terraform Up And Running
#+date: [2022-03-01 ter 21:10]
#+edition: 2nd
#+bibliography: "../bib/Terraform_Up_Running.bibtex"

+ What is Terraform?

Terraform is an open source tool created by HashiCorp that allows you to define
your infrastructure as code using a simple, declarative language and to deploy
and manage that infrastructure across a variety of public cloud providers (e.g.,
AWS, Azure, GCP, DigitalOcean) and private cloud and virtualization platforms
(e.g., OpenStack, VMWare) using a few commands.

Terraform is an open source tool created by Hashicorp and written in the Go
programming language.

+ Where to find this book codes? [[https://github.com/brikis98/terraform-up-and-running-code][Book's github repository]].
+ [[https://registry.terraform.io/providers/hashicorp/azurerm/latest/docs][Azure resources]].

* 1 - Why Terraform

  [...] Software isn't done until you deliver it to the user.

  Software delivery consists of all of the work you need to do to make the code
  available to a customer, such as running that code on production servers,
  making the code resilient to outages and traffic spikes, and protecting the
  code from attackers.

  Some tools to keep an eye on:

  + Chef
  + Puppet
  + Terraform
  + Docker

  DevOps definition adopted by this book author:

  + The goal of DevOps is to make software delivery vastly more efficient.

  Instead of multiday merge nightmares, you integrate code continuously and
  always keep it in a deployable state. Instead of deploying code once per
  month, you can deploy code dozens of times per day, or even after every single
  commit. And instead of constant outages and downtime, you build resilient,
  self-healing systems and use monitoring and alerting to catch problems that
  can't be resolved automatically.

** IAC (Infrastructure As Code)

   The idea behind IAC is that you write and execute code to define, deploy,
   update, and destroy your infrastructure. [...] In fact, a key insight of
   DevOps is that you can manage almost everything in code, including servers,
   databases, networks, log files, application configuration, documentation,
   automated tests, deployment processes, and so on.

   There are five broad categories of IAC tools that I'll write some notes next.

*** Ad Hoc Scripts

    This is the most straighforward approach to automate anything. You take
    whatever task you were doing manually, break it down into discrete steps,
    use your favorite scripting language (e.g., Bash, Ruby, Python) to define
    each of those steps in code, and execute that script on your server.

*** Configuration Management Tools

    Chef, Puppet, Ansible, and SaltStack are all configuration management tools,
    which means that they are designed to install and manage software on
    existing servers.

*** Server Templating Tools

    An alternative to configuration management that has been growing in
    popularity recently are server templating tools such as Docker, Packer, and
    Vagrant. Instead of launching a bunch of server and configuring them by
    running the same code on each one, the idea behind server templating tools
    is to create an image of the server that captures a fully self-contained
    "snapshot" of the operating system (OS), the software, the files, and all
    other relevant details.

*** Orchestration Tools

    For most real-world use cases, you'll need a way to do the following:

    - Deploy VMs and containers, making efficient use of your hardware.
    - Roll out updates to an existing fleet of VMs and containers using strategies
      such as rolling deployment, blue-green deployment, and canary deployment.
    - Monitor the health of your VMs and containers and automatically replace
      unhealthy ones (auto healing).
    - Scale the number of VMs and containers up or down in response to load (auto
      scaling).
    - Distribute traffic across your VMs and containers (load balancing).
    - Allows your VMs and containers to find and talk one another over the network
      (service discovery).

    Handling these tasks is the realm of orchestration tools such as Kubernetes,
    Marathon/Mesos, Amazon Elastic Container Service (Amazon ECS), Docker Swarm,
    Nomad, AKS.

*** Provisioning Tools

    Whereas configuration management, server templating, and orchestration tools
    define the code that runs on each server, provisioning tools such as
    Terraform, CloudFormation, and OpenStack Heat are responsible for creating
    the servers themselves. In fact, you can use provisioning tools to not only
    create servers, but also databases, caches, load balancers, queues,
    monitoring, subnet configurations, firewall settings, routing rules, Secure
    Sockets Layer (SSL) certificates, and almost every other aspect of your
    infrastructure.

** The benefits of IAC

   According to the 2016 State of DevOps Report, organizations that use DevOps
   practices, such as IaC, deploy 200 times more frequently, recover from
   failures 24 times faster, and have lead times that are 2,555 times lower.

* 2 - Getting Started with Terraform

  In this chapter, you're going to learn the basics of how to use Terraform.

** Deploy a Single Server

   Terraform code is written in the HashiCorp Configuration Language (HCL) in
   files with the extension /.tf/. It is a declarative language, so your goal is
   to describe the infrastructure you want, and Terraform will figure out how to
   create it.
  
   #+begin_src hcl :file main.tf
     variable "server_port" {
       description = "The port the server will use for HTTP requests"
       type        = number
       default     = 8080
     }

     output "public_ip" {
       value       = aws_instance.example.public_ip
       description = "The public IP address of the web server"
     }

     provider "aws" {
       region = "us-east-2"
     }

     # ami -> Amazon Machine Image
     # set this machine name
     # start a new http server listening in port 8080
     resource "aws_instance" "example" {
       ami           = "ami-0c55b159cbfafe1f0"
       instance_type = "t2.micro"
       vpc_security_group_ids = [aws_security_group.instance.id]

       user_data = <<-EOF
                   #!/bin/bash
                   echo "Hello, World" > index.html
                   nohup busybox httpd -f -p ${var.server_port} &
                   EOF

       tags = {
         Name = "terraform-example"
       }
     }

     # AWS does not allow any incoming or outgoing traffic from an
     # EC2 instance.
     resource "aws_security_group" "instance" {
       name = "terraform-example-instance"

       ingress {
         from_port   = var.server_port
         to_port     = var.server_port
         protocol    = "tcp"
         # CIDR blocks are a concise way to specify IP addr ranges
         cidr_blocks = ["0.0.0.0/0"]
       }
     }
   #+end_src

   [...]

   The reason to use big numbered ports to expose projects is that listening on
   any port less than 1024 requires root user privileges. This is a security
   risk, because any attacker who manages to compromise your server would get
   root privileges, too.

   [...]

   The <<-EOF and EOF are Terraform's /heredoc/ syntax, which allows you to
   create multiline strings without having to insert newline characters all over
   the place.

   [...]

   When Terraform walks your dependency tree, it creates as many resources in
   parallel as it can, which means that it can apply your changes faily
   efficiently. That's the beauty of a declarative language: you just specify
   what you want and Terraform determines the most efficient way to make it
   happen.

** Deploy a cluster of web servers

   Managing a cluster manually is a lot of work. Fortunately, you can let AWS
   take care of it for by you using an Auto Scaling Group (ASG).
   
   #+begin_src hcl :file main.tf
     variable "server_port" {
       description = "The port the server will use for HTTP requests"
       type        = number
       default     = 8080
     }

     output "public_ip" {
       value       = aws_instance.example.public_ip
       description = "The public IP address of the web server"
     }

     data "aws_vpc" "default" {
       default = true
     }

     data "aws_subnet_ids" "default" {
       vpc_id = data.aws_vpc.default.id
     }

     provider "aws" {
       region = "us-east-2"
     }

     # ami -> Amazon Machine Image
     # set this machine name
     # start a new http server listening in port 8080
     resource "aws_launch_configuration" "example" {
       ami            = "ami-0c55b159cbfafe1f0"
       instance_type  = "t2.micro"
       security_group = [aws_security_group.instance.id]

       user_data = <<-EOF
                   #!/bin/bash
                   echo "Hello, World" > index.html
                   nohup busybox httpd -f -p ${var.server_port} &
                   EOF

       # Required when using a launch configuration with an auto scaling group.
       # https://www.terraform.io/docs/providers/aws/r/launch_configuration.html
       lifecycle {
         create_before_destroy = true
       }

       tags = {
         Name = "terraform-example"
       }
     }

     resource "aws_autoscalling_group" "example" {
       launch_configuration = aws_launch_configuration.example.name
       vpc_zone_identifier  = data.aws_subnet.ids.default.ids

       min_size = 2
       max_size = 10

       tag {
         key                 = "Name"
         value               = "terraform-asg-example"
         propagate_at_launch = true
       }
     }

     # AWS does not allow any incoming or outgoing traffic from an
     # EC2 instance.
     resource "aws_security_group" "instance" {
       name = "terraform-example-instance"

       ingress {
         from_port   = var.server_port
         to_port     = var.server_port
         protocol    = "tcp"
         # CIDR blocks are a concise way to specify IP addr ranges
         cidr_blocks = ["0.0.0.0/0"]
       }
     }
   #+end_src

** Deploying a Load Balancer

   At this point, you can deploy your ASG, but you'll have a small problem: you
   now have multiple servers, each with its own IP address, but you typically
   want to give of your end users only a single IP to use. One way to solve this
   problem is to deploy a /load balancer/ to distribute traffic across your
   servers and to give all your users the IP (actually, the DNS name) of the
   load balancer. [...] Once again, you can let AWS take care of it for you,
   this time by using Amazon's /Elastic Load Balancer/ (ELB) service.

   #+begin_src hcl :file main.tf
     variable "server_port" {
       description = "The port the server will use for HTTP requests"
       type        = number
       default     = 8080
     }

     output "public_ip" {
       value       = aws_instance.example.public_ip
       description = "The public IP address of the web server"
     }

     data "aws_vpc" "default" {
       default = true
     }

     data "aws_subnet_ids" "default" {
       vpc_id = data.aws_vpc.default.id
     }

     provider "aws" {
       region = "us-east-2"
     }

     # ami -> Amazon Machine Image
     # set this machine name
     # start a new http server listening in port 8080
     resource "aws_launch_configuration" "example" {
       ami            = "ami-0c55b159cbfafe1f0"
       instance_type  = "t2.micro"
       security_group = [aws_security_group.instance.id]

       user_data = <<-EOF
                   #!/bin/bash
                   echo "Hello, World" > index.html
                   nohup busybox httpd -f -p ${var.server_port} &
                   EOF

       # Required when using a launch configuration with an auto scaling group.
       # https://www.terraform.io/docs/providers/aws/r/launch_configuration.html
       lifecycle {
         create_before_destroy = true
       }

       tags = {
         Name = "terraform-example"
       }
     }

     resource "aws_autoscalling_group" "example" {
       launch_configuration = aws_launch_configuration.example.name
       vpc_zone_identifier  = data.aws_subnet.ids.default.ids

       min_size = 2
       max_size = 10

       tag {
         key                 = "Name"
         value               = "terraform-asg-example"
         propagate_at_launch = true
       }
     }

     resource "aws_lb" "example" {
       name               = "terraform-asg-example"
       load_balancer_type = "application"
       subnets            = data.aws_subnet_ids.default.ids
       security_groups    = [aws_security_group.alb.id]
     }

     resource "aws_lb_listener" "http" {
       load_balancer_arn = aws_lb.example.arn
       port              = 80
       protocol          = "HTTP"

       # By default, return a simple 404 page
       default_action {
         type = "fixed-response"

         fixed_response {
           content_type = "text/plain"
           message_body = "404: page not found"
           status_code  = 404
         }
       }
     }

     resource "aws_security_group" "alb" {
       name = "terraform-example-alb"

       ingress {
         from_port   = 80
         to_port     = 80
         protocol    = "tcp"
         # CIDR blocks are a concise way to specify IP addr ranges
         cidr_blocks = ["0.0.0.0/0"]
       }

       # Allow all outbound requests
       egress {
         from_port = 0
         to_port = 0
         protocol = "-1"
         cidr_blocks = ["0.0.0.0/0"]
       }
     }

     resource "aws_lb_target_group" "asg" {
       name     = "terraform-asg-example"
       port     = var.server_port
       protocol = "HTTP"
       vpc_id   = data.aws_vpc.default.id

       health_check {
         path                = "/"
         protocol            = "HTTP"
         matcher             = "200"
         interval            = 15
         timeout             = 3
         healthy_threshold   = 2
         unhealthy_threshold = 2
       }
     }

     # AWS does not allow any incoming or outgoing traffic from an
     # EC2 instance.
     resource "aws_security_group" "instance" {
       name = "terraform-example-instance"

       ingress {
         from_port   = var.server_port
         to_port     = var.server_port
         protocol    = "tcp"
         # CIDR blocks are a concise way to specify IP addr ranges
         cidr_blocks = ["0.0.0.0/0"]
       }
     }
   #+end_src

** Terraform commands

    How to run this?

   #+begin_src shell
     # install provider code (AWS, Azure, GCP, etc)
     # will save it in .terraform folder
     # one could add this folder to the gitignore
     $ terraform init # this command is idempotent

     # see what Terraform will do before actually making changes
     $ terraform plan # sanity check

     # create the instance
     $ terraform apply

     # show the dependency graph for the operation
     # output is in a graph description lang called DOT
     $ terraform graph

     # see just the output of a configuration
     $ terraform output

     # destroy services
     # WARNING: there's no undo for this command
     $ terraform destroy
   #+end_src

   What are the files that we should put in the gitignore?

   #+begin_src txt
     .terraform
     *.tfstate
     *.tfstate.backup
   #+end_src

* 3 - How to Manage Terraform State

  Previously when we were using Terraform to create and update resources, one
  must notice that every time we ran /terraform plan/ or /terraform apply/,
  Terraform was able to find the resources it created previously and update them
  accordingly. This is totally related to Terraform state.

** What is Terraform state?

   Every time you run Terraform, it records information about what
   infrastructure it created in a Terraform state file (/terraform.tfstate/ file
   in the root directory the command is triggered).

   This /tfstate/ file contains a custom JSON format that records a mapping from
   the Terraform resources in your configuration files to the representation of
   those resources in the real world.
